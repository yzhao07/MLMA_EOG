{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f75e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import librosa\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3166f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "def get_original_feature_label(path):\n",
    "    # scale both vertical and horizontal between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    feature = []\n",
    "    label = []\n",
    "    for i in os.listdir(path):\n",
    "        a = pd.read_csv(str(path+i),names=[\"vertical\",\"horizontal\"])\n",
    "        a = np.array(a)\n",
    "        a = scaler.fit_transform(a)\n",
    "        #print(str(\"../data/isolated 2/001/isolated_strokes/\"+i))\n",
    "        f = []\n",
    "        for j in a[:,0]:\n",
    "            f.append(j)\n",
    "        for j in a[:,1]:\n",
    "            f.append(j)\n",
    "        feature.append(f)\n",
    "        if i.endswith(\"001.csv\"):\n",
    "            label.append(0)\n",
    "        elif i.endswith(\"002.csv\"):\n",
    "            label.append(1)\n",
    "        elif i.endswith(\"003.csv\"):\n",
    "            label.append(2)\n",
    "        elif i.endswith(\"004.csv\"):\n",
    "            label.append(3)\n",
    "        elif i.endswith(\"005.csv\"):\n",
    "            label.append(4)\n",
    "        elif i.endswith(\"006.csv\"):\n",
    "            label.append(5)\n",
    "        elif i.endswith(\"007.csv\"):\n",
    "            label.append(6)\n",
    "        elif i.endswith(\"008.csv\"):\n",
    "            label.append(7)\n",
    "        elif i.endswith(\"009.csv\"):\n",
    "            label.append(8)\n",
    "        elif i.endswith(\"010.csv\"):\n",
    "            label.append(9)\n",
    "        elif i.endswith(\"011.csv\"):\n",
    "            label.append(10)\n",
    "        elif i.endswith(\"012.csv\"):\n",
    "            label.append(11)\n",
    "    feature = np.array(feature)\n",
    "    label = np.array(label)\n",
    "    \n",
    "    return feature,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8563e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split 8:2 \n",
    "def my_train_split(label,feature):\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(12):\n",
    "        id = np.where(label==i)\n",
    "        tmplabel = label[id]\n",
    "        tmpfeature = feature[id]\n",
    "        tmpX_train, tmpX_test, tmpy_train, tmpy_test = train_test_split(tmpfeature, tmplabel,shuffle=True, test_size=0.2, random_state=42)\n",
    "        for j in range(len(tmpy_train)):\n",
    "            X_train.append(tmpX_train[j])\n",
    "            y_train.append(tmpy_train[j])\n",
    "        for j in range(len(tmpy_test)):\n",
    "            X_test.append(tmpX_test[j])\n",
    "            y_test.append(tmpy_test[j])\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    idx = list(range(X_train.shape[0]))\n",
    "    random.seed(42)\n",
    "    random.shuffle(idx)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    return X_train,X_test,y_train,y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db385da",
   "metadata": {},
   "source": [
    "## User dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa7393bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2500)\n",
      "0.9166666666666666\n",
      "(120, 2500)\n",
      "0.875\n",
      "(122, 2500)\n",
      "0.7307692307692307\n",
      "(121, 2500)\n",
      "0.84\n",
      "(120, 2500)\n",
      "0.88\n",
      "(121, 2500)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "output_pck = []\n",
    "for i in patient:\n",
    "    feature,label = get_original_feature_label(str(\"../../data/isolated 2/\"+i+\"/isolated_strokes/\"))\n",
    "    print(feature.shape)\n",
    "    # train_test_split\n",
    "    X_train,X_test,y_train,y_test = my_train_split(label,feature)\n",
    "    # build model\n",
    "    clf = svm.SVC(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))    \n",
    "    output = dict()\n",
    "    output[\"patient\"] = i\n",
    "    output[\"X_train\"] = X_train\n",
    "    output[\"X_test\"] = X_test\n",
    "    output[\"y_test\"] = y_test\n",
    "    output[\"y_train\"] = y_train\n",
    "    output[\"clf\"] = clf\n",
    "    output_pck.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0cf77e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the object\n"
     ]
    }
   ],
   "source": [
    "print('\\nSaving the object')\n",
    "with open(\"User-dependent-SVC.pck\", \"wb\") as output_file:\n",
    "    pickle.dump(output_pck, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ccf67",
   "metadata": {},
   "source": [
    "## User independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71f368e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 2500) (724,)\n"
     ]
    }
   ],
   "source": [
    "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "feature = []\n",
    "label = []\n",
    "for i in patient:\n",
    "    f,l = get_original_feature_label(str(\"../../data/isolated 2/\"+i+\"/isolated_strokes/\"))\n",
    "    for x in f:\n",
    "        feature.append(x)         \n",
    "    for x in l:\n",
    "        label.append(x)\n",
    "feature = np.array(feature)\n",
    "label = np.array(label)\n",
    "print(feature.shape,label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f71d3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657718120805369\n"
     ]
    }
   ],
   "source": [
    "# train_test_split\n",
    "X_train,X_test,y_train,y_test = my_train_split(label,feature)\n",
    "# build model\n",
    "clf = svm.SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "233c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the object\n"
     ]
    }
   ],
   "source": [
    "output = dict()\n",
    "output[\"X_train\"] = X_train\n",
    "output[\"X_test\"] = X_test\n",
    "output[\"y_test\"] = y_test\n",
    "output[\"y_train\"] = y_train\n",
    "output[\"clf\"] = clf\n",
    "print('\\nSaving the object')\n",
    "with open(\"User-independent-SVC.pck\", \"wb\") as output_file:\n",
    "    pickle.dump(output, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c100939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
