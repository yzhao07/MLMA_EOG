{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f75e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import librosa\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score\n",
    "from preprocess import preprocess\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3166f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file list for 1 patient\n",
    "def get_file_list(path):\n",
    "    file_list = []\n",
    "    label = []\n",
    "    for i in os.listdir(path):\n",
    "        file_list.append(i)\n",
    "        l = int(i.split(\"_\")[-1].split(\".\")[0])-1\n",
    "        label.append(l)\n",
    "    return label,file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27ecdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature from 1 file and preprocess\n",
    "def get_feature(path):\n",
    "    f = []\n",
    "    a = pd.read_csv(path,names=[\"vertical\",\"horizontal\"])\n",
    "    a = np.array(a)\n",
    "    #print(a.shape)\n",
    "    a = preprocess(a)\n",
    "    #print(a.shape)\n",
    "    for j in a[:,0]:\n",
    "        f.append(j)        \n",
    "    for j in a[:,1]:\n",
    "        f.append(j)\n",
    "    return f\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e54423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self identified test_split\n",
    "def my_train_test_split_user_dependent(path,test_split,val_split,file_list,label):\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for f in range(len(file_list)):\n",
    "        file = file_list[f]\n",
    "        file_label = label[f]\n",
    "        #print(file)\n",
    "        feature = get_feature(str(path+file))\n",
    "        #print(file.split('_')[2],file_label)\n",
    "        if file.split('_')[2] in test_split:\n",
    "            X_test.append(feature)\n",
    "            y_test.append(file_label)\n",
    "            #print(file,len(feature))\n",
    "        elif file.split('_')[2] == val_split:\n",
    "            X_val.append(feature)\n",
    "            y_val.append(file_label)\n",
    "        else:\n",
    "            X_train.append(feature)\n",
    "            y_train.append(file_label)\n",
    "            #print(file)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_train = np.array(y_train)\n",
    "    y_val = np.array(y_val)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train,X_test,X_val,y_val, y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cb4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred,y_prob):\n",
    "    f1_micro = f1_score(y_true, y_pred,average = 'micro')\n",
    "    f1_macro = f1_score(y_true, y_pred,average = 'macro')\n",
    "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
    "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    #cm = confusion_matrix(y_true, y_pred)\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "     #                         display_labels=[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "    #disp.plot()\n",
    "    #plt.show()\n",
    "    #class_accuracy = cm.diagonal()/cm.sum(axis=1)\n",
    "    #specificity = class_accuracy[1]\n",
    "    #sensitivity = class_accuracy[0]\n",
    "    auc = roc_auc_score(y_true,y_prob,multi_class=\"ovr\",average=\"micro\")\n",
    "\n",
    "    return f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db385da",
   "metadata": {},
   "source": [
    "## User dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bac6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "test_split = [[\"01\",\"02\"],[\"03\",\"04\"],[\"05\",\"06\"],[\"07\",\"08\"],[\"09\",\"10\"]]\n",
    "val_split = ['03','01',\"04\",\"05\",\"06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b70d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train,X_test, X_val,y_val,y_train,y_test):\n",
    "    C = [0.01,1,100]\n",
    "    kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    grid_search_output = []\n",
    "    for c in C:\n",
    "        for k in kernel:\n",
    "            output = dict()\n",
    "            output[\"C\"] = c\n",
    "            output[\"kernal\"] = k\n",
    "            clf = svm.SVC(C=c,kernel = k,probability=True,random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = clf.predict(X_val)\n",
    "            y_prob = clf.predict_proba(X_val)\n",
    "            f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc = evaluate(y_val, y_pred,y_prob)\n",
    "            output[\"model\"] = clf\n",
    "            output[\"val_Accuracy\"] = acc\n",
    "            output[\"val_f1_micro\"] = f1_micro\n",
    "            output[\"val_f1_macro\"] = f1_macro\n",
    "            output[\"val_precision_micro\"]= precision_micro\n",
    "            output[\"val_precision_macro\"]= precision_macro\n",
    "            output[\"val_recall_micro\"]= recall_micro\n",
    "            output[\"val_recall_macro\"]= recall_macro\n",
    "            \n",
    "            \n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)\n",
    "            f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc = evaluate(y_test, y_pred,y_prob)\n",
    "            output[\"test_Accuracy\"] = acc\n",
    "            output[\"test_f1_micro\"] = f1_micro\n",
    "            output[\"test_f1_macro\"] = f1_macro\n",
    "            output[\"test_precision_micro\"]= precision_micro\n",
    "            output[\"test_precision_macro\"]= precision_macro\n",
    "            output[\"test_recall_micro\"]= recall_micro\n",
    "            output[\"test_recall_macro\"]= recall_macro\n",
    "            grid_search_output.append(output)\n",
    "    return grid_search_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "284ec821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n",
      "002\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n",
      "003\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n",
      "004\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n",
      "005\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n",
      "006\n",
      "['01', '02']\n",
      "(12, 200) (12,)\n",
      "['03', '04']\n",
      "(12, 200) (12,)\n",
      "['05', '06']\n",
      "(12, 200) (12,)\n",
      "['07', '08']\n",
      "(12, 200) (12,)\n",
      "['09', '10']\n",
      "(12, 200) (12,)\n"
     ]
    }
   ],
   "source": [
    "for p in patient:\n",
    "    print(p)\n",
    "    output_pck = []\n",
    "    path = str(\"../../../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "    for t in range(len(test_split)):\n",
    "        print(test_split[t])\n",
    "        label,file_list = get_file_list(path)\n",
    "        X_train,X_test,X_val,y_val, y_train,y_test = my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)\n",
    "        print(X_val.shape,y_val.shape)\n",
    "         # build model\n",
    "        # set parameter \n",
    "        output = dict()\n",
    "        output[\"test_split\"] = t\n",
    "        grid_search_output = grid_search(X_train,X_test, X_val,y_val,y_train,y_test)\n",
    "        output[\"grid_search\"] = grid_search_output\n",
    "        output_pck.append(output)\n",
    "        \n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"wb\") as output_file:\n",
    "        pickle.dump(output_pck, output_file)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb0f94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameter = dict()\n",
    "for p in patient:\n",
    "    #print(p)\n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "    C = [0.01,1,100]\n",
    "    kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    grid_search_output = []\n",
    "\n",
    "    \n",
    "    for c in C:\n",
    "        for k in kernel:\n",
    "            #print(\"C:\",c,\" kernel:\",k)\n",
    "\n",
    "            acc = 0\n",
    "            f1 = 0\n",
    "            recall = 0\n",
    "            precision = 0\n",
    "            count = 0\n",
    "            for i in range(len(pck)):\n",
    "                tmp = pck[i][\"grid_search\"]\n",
    "                for j in range(len(tmp)):\n",
    "                    tmp_tesult = tmp[j]\n",
    "                    if tmp_tesult['C'] == c and tmp_tesult['kernal'] == k:\n",
    "                        acc += tmp_tesult['val_Accuracy']\n",
    "                        f1 += tmp_tesult['val_f1_macro']\n",
    "                        recall += tmp_tesult['val_recall_macro']\n",
    "                        precision += tmp_tesult['val_precision_macro']\n",
    "                        count+=1\n",
    "#             print(\"Accuracy:\",round(acc/count,2),\n",
    "#                   \"F1:\",round(f1/count,2),\n",
    "#                  \"auc:\",round(auc/count,2),\n",
    "#                  \"precision:\",round(precision/count,2),\n",
    "#                  \"recall:\",round(recall/count,2),)\n",
    "            if str(\"C:\"+str(c)+\" kernel:\"+k) in parameter:\n",
    "                parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] += f1/count\n",
    "            else:\n",
    "                #print(str(\"C:\"+str(c)+\" kernel:\"+k))\n",
    "                parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] = f1/count\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f81ee31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:0.01 kernel:linear': 3.646190476190476,\n",
       " 'C:0.01 kernel:poly': 3.705,\n",
       " 'C:0.01 kernel:rbf': 1.6328133903133901,\n",
       " 'C:0.01 kernel:sigmoid': 0.3834110334110334,\n",
       " 'C:1 kernel:linear': 4.965,\n",
       " 'C:1 kernel:poly': 4.896666666666667,\n",
       " 'C:1 kernel:rbf': 4.7316666666666665,\n",
       " 'C:1 kernel:sigmoid': 0.509066674066674,\n",
       " 'C:100 kernel:linear': 4.9816666666666665,\n",
       " 'C:100 kernel:poly': 4.930000000000001,\n",
       " 'C:100 kernel:rbf': 5.042777777777777,\n",
       " 'C:100 kernel:sigmoid': 0.46675925925925915}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c501cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bester parameter C:100 kernel:rbf\n",
      "best f1 score 0.8404629629629629\n"
     ]
    }
   ],
   "source": [
    "print(\"bester parameter\",list(parameter.keys())[list(parameter.values()).index(max(parameter.values()))])\n",
    "print(\"best f1 score\", max(parameter.values())/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35591aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8735507246376808\n",
      "f1_macro 0.865952380952381\n",
      "f1_micro 0.8735507246376808\n",
      "recall_micro 0.8735507246376808\n",
      "recall_macro 0.8736111111111107\n",
      "precision_micro 0.8735507246376808\n",
      "precision_macro 0.8941203703703703\n"
     ]
    }
   ],
   "source": [
    "# report test data\n",
    "count = 0\n",
    "acc = 0\n",
    "f1_micro = 0\n",
    "f1_macro = 0\n",
    "recall_micro = 0\n",
    "recall_macro = 0\n",
    "precision_micro = 0\n",
    "precision_macro = 0\n",
    "for p in patient:\n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "    for i in range(len(pck)):\n",
    "        tmp = pck[i][\"grid_search\"]\n",
    "        for j in range(len(tmp)):\n",
    "            tmp_tesult = tmp[j]\n",
    "            if tmp_tesult['C'] == 100 and tmp_tesult['kernal'] == 'rbf':\n",
    "                #print(tmp_tesult['test_Accuracy'],tmp_tesult['test_F1'],tmp_tesult['test_recall'], tmp_tesult['test_precision'])\n",
    "                acc += tmp_tesult['test_Accuracy']\n",
    "                f1_macro += tmp_tesult['test_f1_macro']\n",
    "                f1_micro += tmp_tesult['test_f1_micro']\n",
    "                recall_micro += tmp_tesult['test_recall_micro']\n",
    "                recall_macro += tmp_tesult['test_recall_macro']\n",
    "                precision_micro += tmp_tesult['test_precision_micro']\n",
    "                precision_macro += tmp_tesult['test_precision_macro']\n",
    "                count+=1\n",
    "\n",
    "print(\"acc\",acc/count)\n",
    "print(\"f1_macro\",f1_macro/count)\n",
    "print(\"f1_micro\",f1_micro/count)\n",
    "print(\"recall_micro\",recall_micro/count)\n",
    "print(\"recall_macro\",recall_macro/count)\n",
    "print(\"precision_micro\",precision_micro/count)\n",
    "print(\"precision_macro\",precision_macro/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5790ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120\n",
      "120 120\n",
      "122 122\n",
      "121 121\n",
      "120 120\n",
      "121 121\n"
     ]
    }
   ],
   "source": [
    "for p in patient:\n",
    "    \n",
    "    path = str(\"../../../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    X = []\n",
    "    y = []\n",
    "    for f in range(len(file_list)):\n",
    "        file = file_list[f]\n",
    "        file_label = label[f]\n",
    "        #print(file)\n",
    "        feature = get_feature(str(path+file))\n",
    "        X.append(feature)\n",
    "        y.append(file_label)\n",
    "    print(len(X),len(y))\n",
    "    clf = svm.SVC(C=100,kernel = 'rbf',probability=True,random_state=42)\n",
    "    clf.fit(X, y)  \n",
    "    with open(str(\"../Isolated Model/SVC__sub\"+p+\".pck\"), \"wb\") as output_file:\n",
    "        pickle.dump(clf, output_file)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ccf67",
   "metadata": {},
   "source": [
    "## User independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self identified test_split\n",
    "def my_train_test_split_user_independent(test_patient,val_patient,train_patient):\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for p in train_patient:\n",
    "        path = str(\"../../../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "        label,file_list = get_file_list(path)\n",
    "        for i in range(len(file_list)):\n",
    "            file = file_list[i]\n",
    "            file_label = label[i]\n",
    "            feature = get_feature(str(path+file))\n",
    "            X_train.append(feature)\n",
    "            y_train.append(file_label)\n",
    "        \n",
    "    path = str(\"../../../../data/isolated 2/\"+test_patient+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    for i in range(len(file_list)):\n",
    "        file = file_list[i]\n",
    "        file_label = label[i]\n",
    "        feature = get_feature(str(path+file))\n",
    "        X_test.append(feature)\n",
    "        y_test.append(file_label)\n",
    "    \n",
    "    path = str(\"../../../../data/isolated 2/\"+val_patient+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    for i in range(len(file_list)):\n",
    "        file = file_list[i]\n",
    "        file_label = label[i]\n",
    "        feature = get_feature(str(path+file))\n",
    "        X_val.append(feature)\n",
    "        y_val.append(file_label)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    return X_train,X_test, X_val,y_val,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "456dbaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 002 ['003', '004', '005', '006']\n",
      "002 003 ['001', '004', '005', '006']\n",
      "003 004 ['001', '002', '005', '006']\n",
      "004 005 ['001', '002', '003', '006']\n",
      "005 006 ['001', '002', '003', '004']\n",
      "006 001 ['002', '003', '004', '005']\n"
     ]
    }
   ],
   "source": [
    "test_patien_list = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "val_patient_list = [\"002\",\"003\",\"004\",\"005\",\"006\",\"001\"]\n",
    "output_pck = []\n",
    "F1 = 0\n",
    " \n",
    "for t in range(len(test_patien_list)):\n",
    "    train_patient= [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "    test_patient = test_patien_list[t]\n",
    "    val_patient = val_patient_list[t]\n",
    "    train_patient.remove(test_patient)\n",
    "    train_patient.remove(val_patient)\n",
    "    print(test_patient,val_patient,train_patient)\n",
    "    X_train,X_test, X_val,y_val,y_train,y_test = my_train_test_split_user_independent(test_patient,val_patient,train_patient)\n",
    "\n",
    "    output = dict()\n",
    "    output[\"test_split\"] = t\n",
    "    grid_search_output = grid_search(X_train,X_test, X_val,y_val,y_train,y_test)\n",
    "    output[\"grid_search\"] = grid_search_output\n",
    "    output_pck.append(output)\n",
    "    \n",
    "\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"wb\") as output_file:\n",
    "    pickle.dump(output_pck, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d5c5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repor best paramter\n",
    "parameter = dict()\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "C = [0.01,1,100]\n",
    "kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in C:\n",
    "    for k in kernel:\n",
    "\n",
    "        f1 = 0\n",
    "        count = 0\n",
    "        for i in range(len(pck)):\n",
    "            tmp = pck[i][\"grid_search\"]\n",
    "            for j in range(len(tmp)):\n",
    "                tmp_tesult = tmp[j]\n",
    "                if tmp_tesult['C'] == c and tmp_tesult['kernal'] == k:\n",
    "\n",
    "                    f1 += tmp_tesult['val_f1_macro']\n",
    "#                         auc+=tmp_tesult['train_AUC']\n",
    "#                         recall += tmp_tesult['train_recall']\n",
    "#                         precision += tmp_tesult['train_precision']\n",
    "                    count+=1\n",
    "#             print(\"Accuracy:\",round(acc/count,2),\n",
    "#                   \"F1:\",round(f1/count,2),\n",
    "#                  \"auc:\",round(auc/count,2),\n",
    "#                  \"precision:\",round(precision/count,2),\n",
    "#                  \"recall:\",round(recall/count,2),)\n",
    "        if str(\"C:\"+str(c)+\" kernel:\"+k) in parameter:\n",
    "            parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] += f1/count\n",
    "        else:\n",
    "                #print(str(\"C:\"+str(c)+\" kernel:\"+k))\n",
    "            parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] = f1/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c100939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:0.01 kernel:linear': 0.5790401756834708,\n",
       " 'C:0.01 kernel:poly': 0.48929764285345806,\n",
       " 'C:0.01 kernel:rbf': 0.13830490171123214,\n",
       " 'C:0.01 kernel:sigmoid': 0.07318836870338591,\n",
       " 'C:1 kernel:linear': 0.6111696348018266,\n",
       " 'C:1 kernel:poly': 0.6114089186586383,\n",
       " 'C:1 kernel:rbf': 0.6635423362540734,\n",
       " 'C:1 kernel:sigmoid': 0.08005649637699712,\n",
       " 'C:100 kernel:linear': 0.5744299301257022,\n",
       " 'C:100 kernel:poly': 0.6033309393524217,\n",
       " 'C:100 kernel:rbf': 0.6371213638672343,\n",
       " 'C:100 kernel:sigmoid': 0.024189134478842564}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b73ab4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bester parameter C:1 kernel:rbf\n",
      "best f1 score 0.6635423362540734\n"
     ]
    }
   ],
   "source": [
    "print(\"bester parameter\",list(parameter.keys())[list(parameter.values()).index(max(parameter.values()))])\n",
    "print(\"best f1 score\", max(parameter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bf822c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.6620284439025125\n",
      "f1_macro 0.633232952168275\n",
      "f1_micro 0.6620284439025125\n",
      "recall_micro 0.6620284439025125\n",
      "recall_macro 0.6626964085297419\n",
      "precision_micro 0.6620284439025125\n",
      "precision_macro 0.7014261530499276\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "count = 0\n",
    "acc = 0\n",
    "f1_micro = 0\n",
    "f1_macro = 0\n",
    "recall_micro = 0\n",
    "recall_macro = 0\n",
    "precision_micro = 0\n",
    "precision_macro = 0\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"rb\") as input_file:\n",
    "    pck = pickle.load(input_file)\n",
    "for i in range(len(pck)):\n",
    "    tmp = pck[i][\"grid_search\"]\n",
    "    for j in range(len(tmp)):\n",
    "        tmp_tesult = tmp[j]\n",
    "        if tmp_tesult['C'] == 1 and tmp_tesult['kernal'] == 'rbf':\n",
    "                #print(tmp_tesult['test_Accuracy'],tmp_tesult['test_F1'],tmp_tesult['test_recall'], tmp_tesult['test_precision'])\n",
    "            acc += tmp_tesult['test_Accuracy']\n",
    "            f1_macro += tmp_tesult['test_f1_macro']\n",
    "            f1_micro += tmp_tesult['test_f1_micro']\n",
    "            recall_micro += tmp_tesult['test_recall_micro']\n",
    "            recall_macro += tmp_tesult['test_recall_macro']\n",
    "            precision_micro += tmp_tesult['test_precision_micro']\n",
    "            precision_macro += tmp_tesult['test_precision_macro']\n",
    "            count+=1\n",
    "\n",
    "print(\"acc\",acc/count)\n",
    "print(\"f1_macro\",f1_macro/count)\n",
    "print(\"f1_micro\",f1_micro/count)\n",
    "print(\"recall_micro\",recall_micro/count)\n",
    "print(\"recall_macro\",recall_macro/count)\n",
    "print(\"precision_micro\",precision_micro/count)\n",
    "print(\"precision_macro\",precision_macro/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d1e89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724 724\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for p in patient:\n",
    "    path = str(\"../../../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    for f in range(len(file_list)):\n",
    "        file = file_list[f]\n",
    "        file_label = label[f]\n",
    "        feature = get_feature(str(path+file))\n",
    "        X.append(feature)\n",
    "        y.append(file_label)\n",
    "print(len(X),len(y))   \n",
    "clf = svm.SVC(C=1,kernel = 'rbf',probability=True,random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "with open(str(\"../Isolated Model/SVC__subAll.pck\"), \"wb\") as output_file:\n",
    "    pickle.dump(clf, output_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691ce3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
