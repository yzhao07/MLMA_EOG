{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f75e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import librosa\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3166f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file list for 1 patient\n",
    "def get_file_list(path):\n",
    "    file_list = []\n",
    "    label = []\n",
    "    for i in os.listdir(path):\n",
    "        file_list.append(i)\n",
    "        if i.endswith(\"001.csv\"):\n",
    "            label.append(0)\n",
    "        elif i.endswith(\"002.csv\"):\n",
    "            label.append(1)\n",
    "        elif i.endswith(\"003.csv\"):\n",
    "            label.append(2)\n",
    "        elif i.endswith(\"004.csv\"):\n",
    "            label.append(3)\n",
    "        elif i.endswith(\"005.csv\"):\n",
    "            label.append(4)\n",
    "        elif i.endswith(\"006.csv\"):\n",
    "            label.append(5)\n",
    "        elif i.endswith(\"007.csv\"):\n",
    "            label.append(6)\n",
    "        elif i.endswith(\"008.csv\"):\n",
    "            label.append(7)\n",
    "        elif i.endswith(\"009.csv\"):\n",
    "            label.append(8)\n",
    "        elif i.endswith(\"010.csv\"):\n",
    "            label.append(9)\n",
    "        elif i.endswith(\"011.csv\"):\n",
    "            label.append(10)\n",
    "        elif i.endswith(\"012.csv\"):\n",
    "            label.append(11)\n",
    "\n",
    "    \n",
    "    return label,file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27ecdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature from 1 file and normalize\n",
    "def get_feature(path):\n",
    "    f = []\n",
    "    scaler = MinMaxScaler()\n",
    "    a = pd.read_csv(path,names=[\"vertical\",\"horizontal\"])\n",
    "    a = np.array(a)\n",
    "    a = scaler.fit_transform(a)\n",
    "    for j in a[:,0]:\n",
    "        f.append(j)        \n",
    "    for j in a[:,1]:\n",
    "        f.append(j)\n",
    "    return f\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e54423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self identified test_split\n",
    "def my_train_test_split_user_dependent(path,test_split,val_split,file_list,label):\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for f in range(len(file_list)):\n",
    "        file = file_list[f]\n",
    "        file_label = label[f]\n",
    "        feature = get_feature(str(path+file))\n",
    "        #print(file.split('_')[2],file_label)\n",
    "        if file.split('_')[2] == test_split:\n",
    "            X_test.append(feature)\n",
    "            y_test.append(file_label)\n",
    "            #print(file,len(feature))\n",
    "        elif file.split('_')[2] == val_split:\n",
    "            X_val.append(feature)\n",
    "            y_val.append(file_label)\n",
    "        else:\n",
    "            X_train.append(feature)\n",
    "            y_train.append(file_label)\n",
    "            #print(file)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_train = np.array(y_train)\n",
    "    y_val = np.array(y_val)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train,X_test,X_val,y_val, y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cb4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred,y_prob):\n",
    "    f1 = f1_score(y_true, y_pred,average = 'micro')\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    #cm = confusion_matrix(y_true, y_pred)\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "     #                         display_labels=[0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "    #disp.plot()\n",
    "    #plt.show()\n",
    "    #class_accuracy = cm.diagonal()/cm.sum(axis=1)\n",
    "    #specificity = class_accuracy[1]\n",
    "    #sensitivity = class_accuracy[0]\n",
    "    auc = roc_auc_score(y_true,y_prob,multi_class=\"ovr\",average=\"micro\")\n",
    "\n",
    "    return f1,precision,recall,acc,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db385da",
   "metadata": {},
   "source": [
    "## User dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bac6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "test_split = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\"]\n",
    "val_split = ['02','03',\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",'01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b70d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train,X_test, X_val,y_val,y_train,y_test):\n",
    "    C = [0.01,1,100]\n",
    "    kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    grid_search_output = []\n",
    "    for c in C:\n",
    "        for k in kernel:\n",
    "            output = dict()\n",
    "            output[\"C\"] = c\n",
    "            output[\"kernal\"] = k\n",
    "            clf = svm.SVC(C=c,kernel = k,probability=True,random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = clf.predict(X_val)\n",
    "            y_prob = clf.predict_proba(X_val)\n",
    "            f1,precision,recall,acc,auc = evaluate(y_val, y_pred,y_prob)\n",
    "            output[\"model\"] = clf\n",
    "            output[\"val_Accuracy\"] = acc\n",
    "            output[\"val_F1\"] = f1\n",
    "            output[\"val_AUC\"] = auc\n",
    "            output[\"val_precision\"]= precision\n",
    "            output[\"val_recall\"]= recall\n",
    "            \n",
    "            \n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)\n",
    "            f1,precision,recall,acc,auc = evaluate(y_test, y_pred,y_prob)\n",
    "            output[\"test_Accuracy\"] = acc\n",
    "            output[\"test_F1\"] = f1\n",
    "            output[\"test_AUC\"] = auc\n",
    "            output[\"test_precision\"]= precision\n",
    "            output[\"test_recall\"]= recall\n",
    "            grid_search_output.append(output)\n",
    "    return grid_search_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284ec821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "002\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "003\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "004\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "005\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "006\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n",
      "(12, 2500) (12,)\n"
     ]
    }
   ],
   "source": [
    "for p in patient:\n",
    "    print(p)\n",
    "    output_pck = []\n",
    "    path = path = str(\"../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "    for t in range(len(test_split)):\n",
    "        label,file_list = get_file_list(path)\n",
    "        X_train,X_test,X_val,y_val, y_train,y_test = my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)\n",
    "        print(X_val.shape,y_val.shape)\n",
    "         # build model\n",
    "        # set parameter \n",
    "        output = dict()\n",
    "        output[\"test_split\"] = t\n",
    "        grid_search_output = grid_search(X_train,X_test, X_val,y_val,y_train,y_test)\n",
    "        output[\"grid_search\"] = grid_search_output\n",
    "        output_pck.append(output)\n",
    "        \n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"wb\") as output_file:\n",
    "        pickle.dump(output_pck, output_file)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcb0f94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameter = dict()\n",
    "for p in patient:\n",
    "    #print(p)\n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "    C = [0.01,1,100]\n",
    "    kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    grid_search_output = []\n",
    "\n",
    "    \n",
    "    for c in C:\n",
    "        for k in kernel:\n",
    "            #print(\"C:\",c,\" kernel:\",k)\n",
    "\n",
    "            acc = 0\n",
    "            f1 = 0\n",
    "            auc = 0\n",
    "            recall = 0\n",
    "            precision = 0\n",
    "            count = 0\n",
    "            for i in range(len(pck)):\n",
    "                tmp = pck[i][\"grid_search\"]\n",
    "                for j in range(len(tmp)):\n",
    "                    tmp_tesult = tmp[j]\n",
    "                    if tmp_tesult['C'] == c and tmp_tesult['kernal'] == k:\n",
    "                        acc += tmp_tesult['val_Accuracy']\n",
    "                        f1 += tmp_tesult['val_F1']\n",
    "                        auc+=tmp_tesult['val_AUC']\n",
    "                        recall += tmp_tesult['val_recall']\n",
    "                        precision += tmp_tesult['val_precision']\n",
    "                        count+=1\n",
    "#             print(\"Accuracy:\",round(acc/count,2),\n",
    "#                   \"F1:\",round(f1/count,2),\n",
    "#                  \"auc:\",round(auc/count,2),\n",
    "#                  \"precision:\",round(precision/count,2),\n",
    "#                  \"recall:\",round(recall/count,2),)\n",
    "            if str(\"C:\"+str(c)+\" kernel:\"+k) in parameter:\n",
    "                parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] += f1/count\n",
    "            else:\n",
    "                #print(str(\"C:\"+str(c)+\" kernel:\"+k))\n",
    "                parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] = f1/count\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f81ee31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:0.01 kernel:linear': 5.333333333333333,\n",
       " 'C:0.01 kernel:poly': 4.231481481481482,\n",
       " 'C:0.01 kernel:rbf': 2.1388888888888893,\n",
       " 'C:0.01 kernel:sigmoid': 0.7037037037037037,\n",
       " 'C:1 kernel:linear': 5.3425925925925934,\n",
       " 'C:1 kernel:poly': 5.287037037037036,\n",
       " 'C:1 kernel:rbf': 5.259259259259259,\n",
       " 'C:1 kernel:sigmoid': 0.8518518518518519,\n",
       " 'C:100 kernel:linear': 5.3425925925925934,\n",
       " 'C:100 kernel:poly': 5.296296296296296,\n",
       " 'C:100 kernel:rbf': 5.379629629629629,\n",
       " 'C:100 kernel:sigmoid': 0.6296296296296297}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43c501cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bester parameter C:100 kernel:rbf\n",
      "best f1 score 0.8966049382716048\n"
     ]
    }
   ],
   "source": [
    "print(\"bester parameter\",list(parameter.keys())[list(parameter.values()).index(max(parameter.values()))])\n",
    "print(\"best f1 score\", max(parameter.values())/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35591aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9012345679012344\n",
      "f1 0.9012345679012344\n",
      "auc 0.9896534792368128\n",
      "recall 0.9012345679012344\n",
      "precision 0.9012345679012344\n"
     ]
    }
   ],
   "source": [
    "# report test data\n",
    "count = 0\n",
    "acc = 0\n",
    "f1 = 0\n",
    "auc = 0\n",
    "recall = 0\n",
    "precision = 0\n",
    "for p in patient:\n",
    "    with open(str(\"./User_dependent/patient_\"+p+\"_SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "    for i in range(len(pck)):\n",
    "        tmp = pck[i][\"grid_search\"]\n",
    "        for j in range(len(tmp)):\n",
    "            tmp_tesult = tmp[j]\n",
    "            if tmp_tesult['C'] == 1 and tmp_tesult['kernal'] == 'linear':\n",
    "                #print(tmp_tesult['test_Accuracy'],tmp_tesult['test_F1'],tmp_tesult['test_recall'], tmp_tesult['test_precision'])\n",
    "                acc += tmp_tesult['test_Accuracy']\n",
    "                f1 += tmp_tesult['test_F1']\n",
    "                auc+=tmp_tesult['test_AUC']\n",
    "                recall += tmp_tesult['test_recall']\n",
    "                precision += tmp_tesult['test_precision']\n",
    "                count+=1\n",
    "\n",
    "print(\"acc\",acc/count)\n",
    "print(\"f1\",f1/count)\n",
    "print(\"auc\",auc/count)\n",
    "print(\"recall\",recall/count)\n",
    "print(\"precision\",precision/count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ccf67",
   "metadata": {},
   "source": [
    "## User independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "706ef201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self identified test_split\n",
    "def my_train_test_split_user_independent(test_patient,val_patient,train_patient):\n",
    "    X_test = []\n",
    "    X_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for p in train_patient:\n",
    "        path = str(\"../../data/isolated 2/\"+p+\"/isolated_strokes/\")\n",
    "        label,file_list = get_file_list(path)\n",
    "        for i in range(len(file_list)):\n",
    "            file = file_list[i]\n",
    "            file_label = label[i]\n",
    "            feature = get_feature(str(path+file))\n",
    "            X_train.append(feature)\n",
    "            y_train.append(file_label)\n",
    "        \n",
    "    path = str(\"../../data/isolated 2/\"+test_patient+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    for i in range(len(file_list)):\n",
    "        file = file_list[i]\n",
    "        file_label = label[i]\n",
    "        feature = get_feature(str(path+file))\n",
    "        X_test.append(feature)\n",
    "        y_test.append(file_label)\n",
    "    \n",
    "    path = str(\"../../data/isolated 2/\"+val_patient+\"/isolated_strokes/\")\n",
    "    label,file_list = get_file_list(path)\n",
    "    for i in range(len(file_list)):\n",
    "        file = file_list[i]\n",
    "        file_label = label[i]\n",
    "        feature = get_feature(str(path+file))\n",
    "        X_val.append(feature)\n",
    "        y_val.append(file_label)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    return X_train,X_test, X_val,y_val,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "456dbaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 002 ['003', '004', '005', '006']\n",
      "002 003 ['001', '004', '005', '006']\n",
      "003 004 ['001', '002', '005', '006']\n",
      "004 005 ['001', '002', '003', '006']\n",
      "005 006 ['001', '002', '003', '004']\n",
      "006 001 ['002', '003', '004', '005']\n"
     ]
    }
   ],
   "source": [
    "test_patien_list = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "val_patient_list = [\"002\",\"003\",\"004\",\"005\",\"006\",\"001\"]\n",
    "output_pck = []\n",
    "F1 = 0\n",
    " \n",
    "for t in range(len(test_patien_list)):\n",
    "    train_patient= [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
    "    test_patient = test_patien_list[t]\n",
    "    val_patient = val_patient_list[t]\n",
    "    train_patient.remove(test_patient)\n",
    "    train_patient.remove(val_patient)\n",
    "    print(test_patient,val_patient,train_patient)\n",
    "    X_train,X_test, X_val,y_val,y_train,y_test = my_train_test_split_user_independent(test_patient,val_patient,train_patient)\n",
    "\n",
    "    output = dict()\n",
    "    output[\"test_split\"] = t\n",
    "    grid_search_output = grid_search(X_train,X_test, X_val,y_val,y_train,y_test)\n",
    "    output[\"grid_search\"] = grid_search_output\n",
    "    output_pck.append(output)\n",
    "    \n",
    "\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"wb\") as output_file:\n",
    "    pickle.dump(output_pck, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d5c5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repor best paramter\n",
    "parameter = dict()\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"rb\") as input_file:\n",
    "        pck = pickle.load(input_file)\n",
    "C = [0.01,1,100]\n",
    "kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in C:\n",
    "    for k in kernel:\n",
    "\n",
    "        f1 = 0\n",
    "        count = 0\n",
    "        for i in range(len(pck)):\n",
    "            tmp = pck[i][\"grid_search\"]\n",
    "            for j in range(len(tmp)):\n",
    "                tmp_tesult = tmp[j]\n",
    "                if tmp_tesult['C'] == c and tmp_tesult['kernal'] == k:\n",
    "\n",
    "                    f1 += tmp_tesult['val_F1']\n",
    "#                         auc+=tmp_tesult['train_AUC']\n",
    "#                         recall += tmp_tesult['train_recall']\n",
    "#                         precision += tmp_tesult['train_precision']\n",
    "                    count+=1\n",
    "#             print(\"Accuracy:\",round(acc/count,2),\n",
    "#                   \"F1:\",round(f1/count,2),\n",
    "#                  \"auc:\",round(auc/count,2),\n",
    "#                  \"precision:\",round(precision/count,2),\n",
    "#                  \"recall:\",round(recall/count,2),)\n",
    "        if str(\"C:\"+str(c)+\" kernel:\"+k) in parameter:\n",
    "            parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] += f1/count\n",
    "        else:\n",
    "                #print(str(\"C:\"+str(c)+\" kernel:\"+k))\n",
    "            parameter[str(\"C:\"+str(c)+\" kernel:\"+k)] = f1/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c100939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:0.01 kernel:linear': 0.6700780156257057,\n",
       " 'C:0.01 kernel:poly': 0.5305762543467462,\n",
       " 'C:0.01 kernel:rbf': 0.27098800975477577,\n",
       " 'C:0.01 kernel:sigmoid': 0.11479775399298499,\n",
       " 'C:1 kernel:linear': 0.598255280073462,\n",
       " 'C:1 kernel:poly': 0.6438940447696035,\n",
       " 'C:1 kernel:rbf': 0.699232827530145,\n",
       " 'C:1 kernel:sigmoid': 0.10064693131012059,\n",
       " 'C:100 kernel:linear': 0.5941115702479339,\n",
       " 'C:100 kernel:poly': 0.6286279335832242,\n",
       " 'C:100 kernel:rbf': 0.6702031492269942,\n",
       " 'C:100 kernel:sigmoid': 0.042780826145207666}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b73ab4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bester parameter C:1 kernel:rbf\n",
      "best f1 score 0.699232827530145\n"
     ]
    }
   ],
   "source": [
    "print(\"bester parameter\",list(parameter.keys())[list(parameter.values()).index(max(parameter.values()))])\n",
    "print(\"best f1 score\", max(parameter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bf822c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.6357191512742929\n",
      "f1 0.6357191512742929\n",
      "auc 0.9362457162462082\n",
      "recall 0.6357191512742929\n",
      "precision 0.6357191512742929\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "count = 0\n",
    "acc = 0\n",
    "f1 = 0\n",
    "auc = 0\n",
    "recall = 0\n",
    "precision = 0\n",
    "with open(str(\"./User_independent/User-independent-SVC.pck\"), \"rb\") as input_file:\n",
    "    pck = pickle.load(input_file)\n",
    "for i in range(len(pck)):\n",
    "    tmp = pck[i][\"grid_search\"]\n",
    "    for j in range(len(tmp)):\n",
    "        tmp_tesult = tmp[j]\n",
    "        if tmp_tesult['C'] == 1 and tmp_tesult['kernal'] == 'linear':\n",
    "                #print(tmp_tesult['test_Accuracy'],tmp_tesult['test_F1'],tmp_tesult['test_recall'], tmp_tesult['test_precision'])\n",
    "            acc += tmp_tesult['test_Accuracy']\n",
    "            f1 += tmp_tesult['test_F1']\n",
    "            auc+=tmp_tesult['test_AUC']\n",
    "            recall += tmp_tesult['test_recall']\n",
    "            precision += tmp_tesult['test_precision']\n",
    "            count+=1\n",
    "\n",
    "print(\"acc\",acc/count)\n",
    "print(\"f1\",f1/count)\n",
    "print(\"auc\",auc/count)\n",
    "print(\"recall\",recall/count)\n",
    "print(\"precision\",precision/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e89aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
