{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8OtYi5RtKQrz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import balanced_accuracy_score,accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkKOjbJwKTyT",
        "outputId": "78255761-ec2a-4fbf-cc60-ee1d59b64649"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = 'drive/MyDrive/23Spring-MLMA/isolated/'\n",
        "os.listdir(main_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAMd0H1dK3BD",
        "outputId": "6cc9e36a-0ba7-43f7-8e51-e84f84999995"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ReadMe',\n",
              " '002',\n",
              " '005',\n",
              " '004',\n",
              " '003',\n",
              " '001',\n",
              " '006',\n",
              " 'XGboost0.pkl',\n",
              " 'XGboost1.pkl',\n",
              " 'XGboost2.pkl',\n",
              " 'XGboost3.pkl',\n",
              " 'XGboost4.pkl',\n",
              " 'XGboost5.pkl',\n",
              " 'XGboost_patient_0model_1.pkl',\n",
              " 'XGboost_patient_0model_3.pkl',\n",
              " 'XGboost_patient_0model_5.pkl',\n",
              " 'XGboost_patient_0model_7.pkl',\n",
              " 'XGboost_patient_0model_9.pkl',\n",
              " 'XGboost_patient_1model_1.pkl',\n",
              " 'XGboost_patient_1model_3.pkl',\n",
              " 'XGboost_patient_1model_5.pkl',\n",
              " 'XGboost_patient_1model_7.pkl',\n",
              " 'XGboost_patient_1model_9.pkl',\n",
              " 'XGboost_patient_2model_1.pkl',\n",
              " 'XGboost_patient_2model_3.pkl',\n",
              " 'XGboost_patient_2model_5.pkl',\n",
              " 'XGboost_patient_2model_7.pkl',\n",
              " 'XGboost_patient_2model_9.pkl',\n",
              " 'XGboost_patient_3model_1.pkl',\n",
              " 'XGboost_patient_3model_3.pkl',\n",
              " 'XGboost_patient_3model_5.pkl',\n",
              " 'XGboost_patient_3model_7.pkl',\n",
              " 'XGboost_patient_3model_9.pkl',\n",
              " 'XGboost_patient_4model_1.pkl',\n",
              " 'XGboost_patient_4model_3.pkl',\n",
              " 'XGboost_patient_4model_5.pkl',\n",
              " 'XGboost_patient_4model_7.pkl',\n",
              " 'XGboost_patient_4model_9.pkl',\n",
              " 'XGboost_patient_5model_1.pkl',\n",
              " 'XGboost_patient_5model_3.pkl',\n",
              " 'XGboost_patient_5model_5.pkl',\n",
              " 'XGboost_patient_5model_7.pkl',\n",
              " 'XGboost_patient_5model_9.pkl',\n",
              " 'RF1.pkl',\n",
              " 'RF0.pkl',\n",
              " 'RF2.pkl',\n",
              " 'RF3.pkl',\n",
              " 'RF4.pkl',\n",
              " 'RF5.pkl',\n",
              " 'RFt_patient_0model_1.pkl',\n",
              " 'RFt_patient_0model_3.pkl',\n",
              " 'RFt_patient_0model_5.pkl',\n",
              " 'RFt_patient_0model_7.pkl',\n",
              " 'RFt_patient_0model_9.pkl',\n",
              " 'RFt_patient_1model_1.pkl',\n",
              " 'RFt_patient_1model_3.pkl',\n",
              " 'RFt_patient_1model_5.pkl',\n",
              " 'RFt_patient_1model_7.pkl',\n",
              " 'RFt_patient_1model_9.pkl',\n",
              " 'RFt_patient_2model_1.pkl',\n",
              " 'RFt_patient_2model_3.pkl',\n",
              " 'RFt_patient_2model_5.pkl',\n",
              " 'RFt_patient_2model_7.pkl',\n",
              " 'RFt_patient_2model_9.pkl',\n",
              " 'RFt_patient_3model_1.pkl',\n",
              " 'RFt_patient_3model_3.pkl',\n",
              " 'RFt_patient_3model_5.pkl',\n",
              " 'RFt_patient_3model_7.pkl',\n",
              " 'RFt_patient_3model_9.pkl',\n",
              " 'RFt_patient_4model_1.pkl',\n",
              " 'RFt_patient_4model_3.pkl',\n",
              " 'RFt_patient_4model_5.pkl',\n",
              " 'RFt_patient_4model_7.pkl',\n",
              " 'RFt_patient_4model_9.pkl',\n",
              " 'RFt_patient_5model_1.pkl',\n",
              " 'RFt_patient_5model_3.pkl',\n",
              " 'RFt_patient_5model_5.pkl',\n",
              " 'RFt_patient_5model_7.pkl',\n",
              " 'RFt_patient_5model_9.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "def get_original_feature_label(path):\n",
        "    # scale both vertical and horizontal between 0 and 1\n",
        "    scaler = MinMaxScaler()\n",
        "    feature = []\n",
        "    label = []\n",
        "    for i in os.listdir(path):\n",
        "        a = pd.read_csv(str(path+i),names=[\"vertical\",\"horizontal\"])\n",
        "        a = np.array(a)\n",
        "        a = scaler.fit_transform(a)\n",
        "        a = np.swapaxes(a,0,1)\n",
        "        feature.append(a)\n",
        "        if i.endswith(\"001.csv\"):\n",
        "            label.append(0)\n",
        "        elif i.endswith(\"002.csv\"):\n",
        "            label.append(1)\n",
        "        elif i.endswith(\"003.csv\"):\n",
        "            label.append(2)\n",
        "        elif i.endswith(\"004.csv\"):\n",
        "            label.append(3)\n",
        "        elif i.endswith(\"005.csv\"):\n",
        "            label.append(4)\n",
        "        elif i.endswith(\"006.csv\"):\n",
        "            label.append(5)\n",
        "        elif i.endswith(\"007.csv\"):\n",
        "            label.append(6)\n",
        "        elif i.endswith(\"008.csv\"):\n",
        "            label.append(7)\n",
        "        elif i.endswith(\"009.csv\"):\n",
        "            label.append(8)\n",
        "        elif i.endswith(\"010.csv\"):\n",
        "            label.append(9)\n",
        "        elif i.endswith(\"011.csv\"):\n",
        "            label.append(10)\n",
        "        elif i.endswith(\"012.csv\"):\n",
        "            label.append(11)\n",
        "    \n",
        "    return feature,label"
      ],
      "metadata": {
        "id": "xnO-Yz1DLKsN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split on patient level - User-independent\n",
        "\n",
        "\n",
        "> 6-fold cross-validation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-btOaAyBLRIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "def train(train_feature,train_label,test_feature,test_label,num):\n",
        "    # 定义模型\n",
        "    model = xgb.XGBClassifier(objective='multi:softmax', num_class=12, random_state=42)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_feature, train_label)\n",
        "\n",
        "    # 预测测试集\n",
        "    y_pred = model.predict(test_feature)\n",
        "\n",
        "    # 计算准确率\n",
        "    accuracy = (y_pred == test_label).sum() / len(test_label)\n",
        "    # auc = roc_auc_score(test_label, y_pred, multi_class='ovr')\n",
        "    average_method = 'macro' # 'macro' 或 'micro' 或 'weighted'\n",
        "    f1 = f1_score(test_label, y_pred,average=average_method)#, multi_class='ovr')\n",
        "    print('Accuracy:', accuracy)\n",
        "    # print('AUC:', auc)\n",
        "    print('F1:', f1)\n",
        "\n",
        "    # 保存模型\n",
        "    pickle.dump(model, open(main_dir+\"XGboost\"+str(num)+\".pkl\", 'wb'))\n",
        "\n",
        "    return accuracy,f1#auc,f1"
      ],
      "metadata": {
        "id": "GourRlsosEd4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "def train(train_feature,train_label,test_feature,test_label,num):\n",
        "    # 定义模型\n",
        "    model = xgb.XGBClassifier(objective='multi:softprob', eval_metric = 'auc',num_class=12, random_state=42)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_feature, train_label)#,eval_set=[(test_feature, test_label)])\n",
        "\n",
        "    # 预测测试集\n",
        "    y_pred = model.predict_proba(test_feature)\n",
        "    # print(np.shape(y_pred))\n",
        "    # print(y_pred)\n",
        "\n",
        "    # 计算准确率\n",
        "    # accuracy = (y_pred == test_label).sum() / len(test_label)\n",
        "    auc = roc_auc_score(test_label, y_pred, multi_class='ovr')\n",
        "    # average_method = 'macro' # 'macro' 或 'micro' 或 'weighted'\n",
        "    # f1 = f1_score(test_label, y_pred,average=average_method)#, multi_class='ovr')\n",
        "    # print('Accuracy:', accuracy)\n",
        "    print('AUC:', auc)\n",
        "    # print('F1:', f1)\n",
        "\n",
        "    # 保存模型\n",
        "    pickle.dump(model, open(main_dir+\"XGboost\"+str(num)+\".pkl\", 'wb'))\n",
        "\n",
        "    return auc#accuracy,f1#auc,f1"
      ],
      "metadata": {
        "id": "kWQbsERoVkfK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "def train(train_feature,train_label,test_feature,test_label,num):\n",
        "    # 定义模型\n",
        "    model = xgb.XGBClassifier(objective='multi:softprob', eval_metric = 'auc',num_class=12, random_state=42)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_feature, train_label)#,eval_set=[(test_feature, test_label)])\n",
        "\n",
        "    # 预测测试集\n",
        "    y_pred_p = model.predict_proba(test_feature)\n",
        "    y_pred = model.predictor(test_feature)\n",
        "\n",
        "    # 计算准确率 auc f1\n",
        "    accuracy = (y_pred == test_label).sum() / len(test_label)\n",
        "    auc = roc_auc_score(test_label, y_pred_p, multi_class='ovr')\n",
        "    average_method = 'macro' # 'macro' 或 'micro' 或 'weighted'\n",
        "    f1 = f1_score(test_label, y_pred,average=average_method)#, multi_class='ovr')\n",
        "    print('Accuracy:', accuracy)\n",
        "    print('AUC:', auc)\n",
        "    print('F1:', f1)\n",
        "\n",
        "    # 保存模型\n",
        "    pickle.dump(model, open(main_dir+\"XGboost\"+str(num)+\".pkl\", 'wb'))\n",
        "\n",
        "    return accuracy, auc, f1"
      ],
      "metadata": {
        "id": "A9w2gngMXw6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_all = [\"001\",'002','003','004','005','006']\n",
        "accl = [];aucl = []; f1l = []\n",
        "for j in range(6):\n",
        "  patient = [patient_all[j]]\n",
        "  test_feature = []\n",
        "  test_label = []\n",
        "  for i in patient:\n",
        "      f,l = get_original_feature_label(str(main_dir+i+\"/isolated_strokes/\"))\n",
        "      for x in f:\n",
        "          test_feature.append(x)         \n",
        "      for x in l:\n",
        "          test_label.append(x)\n",
        "  print(patient)\n",
        "  print(len(test_feature))\n",
        "  test_feature = np.reshape(test_feature,(np.shape(test_feature)[0],-1))\n",
        "\n",
        "  patient = [x for x in patient_all if x != patient_all[j]]\n",
        "  print(patient)\n",
        "  train_feature = []\n",
        "  train_label = []\n",
        "  for i in patient:\n",
        "      f,l = get_original_feature_label(str(main_dir+i+\"/isolated_strokes/\"))\n",
        "      for x in f:\n",
        "          train_feature.append(x)         \n",
        "      for x in l:\n",
        "          train_label.append(x)\n",
        "  print(len(train_feature))\n",
        "  train_feature = np.reshape(train_feature,(np.shape(train_feature)[0],-1))\n",
        "  acc, auc, f1 = train(train_feature,train_label,test_feature,test_label,j)\n",
        "  accl.append(acc)\n",
        "  aucl.append(auc)\n",
        "  f1l.append(f1)\n",
        "  # print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTbU9EPcnf6p",
        "outputId": "1a685cb4-484a-4537-f506-16fdd4601fbb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['001']\n",
            "120\n",
            "['002', '003', '004', '005', '006']\n",
            "604\n",
            "AUC: 0.9242424242424242\n",
            "['002']\n",
            "120\n",
            "['001', '003', '004', '005', '006']\n",
            "604\n",
            "AUC: 0.9872727272727273\n",
            "['003']\n",
            "122\n",
            "['001', '002', '004', '005', '006']\n",
            "602\n",
            "AUC: 0.8887490981240981\n",
            "['004']\n",
            "121\n",
            "['001', '002', '003', '005', '006']\n",
            "603\n",
            "AUC: 0.9090927704564068\n",
            "['005']\n",
            "120\n",
            "['001', '002', '003', '004', '006']\n",
            "604\n",
            "AUC: 0.9597680979561712\n",
            "['006']\n",
            "121\n",
            "['001', '002', '003', '004', '005']\n",
            "603\n",
            "AUC: 0.9712648599012236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(aucl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Io--XuVrml",
        "outputId": "6e098715-739f-4bc1-db01-883820b49552"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9400649963255087"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(accl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umt2zaqpr9xZ",
        "outputId": "00217cb6-505d-4d9c-a8f6-346bf80c6b57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6577718315795812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(aucl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPaLbu1KDZtQ",
        "outputId": "3c743fc1-de64-40c6-f0c4-ab03af6e744e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(f1l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiqFOjJCDdsi",
        "outputId": "16c2ded9-84d8-47b5-9d1e-2f1b521e31f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6360594070761618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User-dependent\n",
        "\n",
        "\n",
        "> 5-fold cross-validation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XqN8XFDOyrjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "def get_original_feature_label(path, t1, t2):\n",
        "    # scale both vertical and horizontal between 0 and 1\n",
        "    scaler = MinMaxScaler()\n",
        "    feature = []\n",
        "    label = []\n",
        "    if t2==0:\n",
        "        num = len(os.listdir(path))-2\n",
        "    else:\n",
        "        num = 2\n",
        "    for i in os.listdir(path):\n",
        "        a = pd.read_csv(str(path+i),names=[\"vertical\",\"horizontal\"])\n",
        "        a = np.array(a)\n",
        "        a = scaler.fit_transform(a)\n",
        "        a = np.swapaxes(a,0,1)\n",
        "        if (t1==1)&(t2!=0)&((i[8:10]==\"01\") or (i[8:10]==\"02\")):\n",
        "            feature.append(a)\n",
        "            if i.endswith(\"001.csv\"):\n",
        "                label.append(0)\n",
        "            elif i.endswith(\"002.csv\"):\n",
        "                label.append(1)\n",
        "            elif i.endswith(\"003.csv\"):\n",
        "                label.append(2)\n",
        "            elif i.endswith(\"004.csv\"):\n",
        "                label.append(3)\n",
        "            elif i.endswith(\"005.csv\"):\n",
        "                label.append(4)\n",
        "            elif i.endswith(\"006.csv\"):\n",
        "                label.append(5)\n",
        "            elif i.endswith(\"007.csv\"):\n",
        "                label.append(6)\n",
        "            elif i.endswith(\"008.csv\"):\n",
        "                label.append(7)\n",
        "            elif i.endswith(\"009.csv\"):\n",
        "                label.append(8)\n",
        "            elif i.endswith(\"010.csv\"):\n",
        "                label.append(9)\n",
        "            elif i.endswith(\"011.csv\"):\n",
        "                label.append(10)\n",
        "            elif i.endswith(\"012.csv\"):\n",
        "                label.append(11)\n",
        "            continue\n",
        "        if (t1==3)&(t2!=0)&((i[8:10]==\"03\") or (i[8:10]==\"04\")):\n",
        "            feature.append(a)\n",
        "            if i.endswith(\"001.csv\"):\n",
        "                label.append(0)\n",
        "            elif i.endswith(\"002.csv\"):\n",
        "                label.append(1)\n",
        "            elif i.endswith(\"003.csv\"):\n",
        "                label.append(2)\n",
        "            elif i.endswith(\"004.csv\"):\n",
        "                label.append(3)\n",
        "            elif i.endswith(\"005.csv\"):\n",
        "                label.append(4)\n",
        "            elif i.endswith(\"006.csv\"):\n",
        "                label.append(5)\n",
        "            elif i.endswith(\"007.csv\"):\n",
        "                label.append(6)\n",
        "            elif i.endswith(\"008.csv\"):\n",
        "                label.append(7)\n",
        "            elif i.endswith(\"009.csv\"):\n",
        "                label.append(8)\n",
        "            elif i.endswith(\"010.csv\"):\n",
        "                label.append(9)\n",
        "            elif i.endswith(\"011.csv\"):\n",
        "                label.append(10)\n",
        "            elif i.endswith(\"012.csv\"):\n",
        "                label.append(11)\n",
        "            continue\n",
        "        if (t1==5)&(t2!=0)&((i[8:10]==\"05\") or (i[8:10]==\"06\")):\n",
        "            feature.append(a)\n",
        "            if i.endswith(\"001.csv\"):\n",
        "                label.append(0)\n",
        "            elif i.endswith(\"002.csv\"):\n",
        "                label.append(1)\n",
        "            elif i.endswith(\"003.csv\"):\n",
        "                label.append(2)\n",
        "            elif i.endswith(\"004.csv\"):\n",
        "                label.append(3)\n",
        "            elif i.endswith(\"005.csv\"):\n",
        "                label.append(4)\n",
        "            elif i.endswith(\"006.csv\"):\n",
        "                label.append(5)\n",
        "            elif i.endswith(\"007.csv\"):\n",
        "                label.append(6)\n",
        "            elif i.endswith(\"008.csv\"):\n",
        "                label.append(7)\n",
        "            elif i.endswith(\"009.csv\"):\n",
        "                label.append(8)\n",
        "            elif i.endswith(\"010.csv\"):\n",
        "                label.append(9)\n",
        "            elif i.endswith(\"011.csv\"):\n",
        "                label.append(10)\n",
        "            elif i.endswith(\"012.csv\"):\n",
        "                label.append(11)\n",
        "            continue\n",
        "        if (t1==7)&(t2!=0)&((i[8:10]==\"07\") or (i[8:10]==\"08\")):\n",
        "            feature.append(a)\n",
        "            if i.endswith(\"001.csv\"):\n",
        "                label.append(0)\n",
        "            elif i.endswith(\"002.csv\"):\n",
        "                label.append(1)\n",
        "            elif i.endswith(\"003.csv\"):\n",
        "                label.append(2)\n",
        "            elif i.endswith(\"004.csv\"):\n",
        "                label.append(3)\n",
        "            elif i.endswith(\"005.csv\"):\n",
        "                label.append(4)\n",
        "            elif i.endswith(\"006.csv\"):\n",
        "                label.append(5)\n",
        "            elif i.endswith(\"007.csv\"):\n",
        "                label.append(6)\n",
        "            elif i.endswith(\"008.csv\"):\n",
        "                label.append(7)\n",
        "            elif i.endswith(\"009.csv\"):\n",
        "                label.append(8)\n",
        "            elif i.endswith(\"010.csv\"):\n",
        "                label.append(9)\n",
        "            elif i.endswith(\"011.csv\"):\n",
        "                label.append(10)\n",
        "            elif i.endswith(\"012.csv\"):\n",
        "                label.append(11)\n",
        "            continue\n",
        "        if (t1==9)&(t2!=0)&((i[8:10]==\"09\") or (i[8:10]==\"10\")):\n",
        "            feature.append(a)\n",
        "            if i.endswith(\"001.csv\"):\n",
        "                label.append(0)\n",
        "            elif i.endswith(\"002.csv\"):\n",
        "                label.append(1)\n",
        "            elif i.endswith(\"003.csv\"):\n",
        "                label.append(2)\n",
        "            elif i.endswith(\"004.csv\"):\n",
        "                label.append(3)\n",
        "            elif i.endswith(\"005.csv\"):\n",
        "                label.append(4)\n",
        "            elif i.endswith(\"006.csv\"):\n",
        "                label.append(5)\n",
        "            elif i.endswith(\"007.csv\"):\n",
        "                label.append(6)\n",
        "            elif i.endswith(\"008.csv\"):\n",
        "                label.append(7)\n",
        "            elif i.endswith(\"009.csv\"):\n",
        "                label.append(8)\n",
        "            elif i.endswith(\"010.csv\"):\n",
        "                label.append(9)\n",
        "            elif i.endswith(\"011.csv\"):\n",
        "                label.append(10)\n",
        "            elif i.endswith(\"012.csv\"):\n",
        "                label.append(11)\n",
        "            continue\n",
        "\n",
        "        if (t1==1)&(t2==0)&((i[8:10]==\"01\") or (i[8:10]==\"02\")):\n",
        "           continue\n",
        "        if (t1==3)&(t2==0)&((i[8:10]==\"03\") or (i[8:10]==\"04\")):\n",
        "           continue\n",
        "        if (t1==5)&(t2==0)&((i[8:10]==\"05\") or (i[8:10]==\"06\")):\n",
        "           continue\n",
        "        if (t1==7)&(t2==0)&((i[8:10]==\"07\") or (i[8:10]==\"08\")):\n",
        "           continue\n",
        "        if (t1==9)&(t2==0)&((i[8:10]==\"09\") or (i[8:10]==\"10\")):\n",
        "           continue\n",
        "\n",
        "        if (t2==0):\n",
        "          feature.append(a)\n",
        "          if i.endswith(\"001.csv\"):\n",
        "              label.append(0)\n",
        "          elif i.endswith(\"002.csv\"):\n",
        "              label.append(1)\n",
        "          elif i.endswith(\"003.csv\"):\n",
        "              label.append(2)\n",
        "          elif i.endswith(\"004.csv\"):\n",
        "              label.append(3)\n",
        "          elif i.endswith(\"005.csv\"):\n",
        "              label.append(4)\n",
        "          elif i.endswith(\"006.csv\"):\n",
        "              label.append(5)\n",
        "          elif i.endswith(\"007.csv\"):\n",
        "              label.append(6)\n",
        "          elif i.endswith(\"008.csv\"):\n",
        "              label.append(7)\n",
        "          elif i.endswith(\"009.csv\"):\n",
        "              label.append(8)\n",
        "          elif i.endswith(\"010.csv\"):\n",
        "              label.append(9)\n",
        "          elif i.endswith(\"011.csv\"):\n",
        "              label.append(10)\n",
        "          elif i.endswith(\"012.csv\"):\n",
        "              label.append(11)\n",
        "        \n",
        "    \n",
        "    return feature,label"
      ],
      "metadata": {
        "id": "U1KV8N6uhofI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "def train(train_feature,train_label,test_feature,test_label,num,p):\n",
        "    # 定义模型\n",
        "    model = xgb.XGBClassifier(objective='multi:softprob', eval_metric = 'auc',num_class=12, random_state=42)\n",
        "\n",
        "    # 训练模型\n",
        "    model.fit(train_feature, train_label)#,eval_set=[(test_feature, test_label)])\n",
        "\n",
        "    # 预测测试集\n",
        "    y_pred_p = model.predict_proba(test_feature)\n",
        "    y_pred = model.predict(test_feature)\n",
        "\n",
        "    # 计算准确率 auc f1\n",
        "    accuracy = (y_pred == test_label).sum() / len(test_label)\n",
        "    auc = roc_auc_score(test_label, y_pred_p, multi_class='ovr')\n",
        "    average_method = 'macro' # 'macro' 或 'micro' 或 'weighted'\n",
        "    f1 = f1_score(test_label, y_pred,average=average_method)#, multi_class='ovr')\n",
        "    print('Accuracy:', accuracy)\n",
        "    print('AUC:', auc)\n",
        "    print('F1:', f1)\n",
        "\n",
        "    # 保存模型\n",
        "    pickle.dump(model, open(main_dir+\"XGboost_patient_\"+str(p)+\"model_\"+str(num)+\".pkl\", 'wb'))\n",
        "\n",
        "    return accuracy,auc,f1"
      ],
      "metadata": {
        "id": "I2HzYAWuX_Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_all = [\"001\",'002','003','004','005','006']\n",
        "acc_p = []; auc_p = []; f1_p = []\n",
        "for j in range(6):\n",
        "\n",
        "  patient_model = patient_all[j]\n",
        "  patient_path = str(main_dir+patient_model+\"/isolated_strokes/\")\n",
        "  accl = []; aucl = []; f1l = []\n",
        "\n",
        "  for i in range(1,10,2):\n",
        "    train_feature = []\n",
        "    train_label = []\n",
        "    f,l = get_original_feature_label(patient_path,i,0)\n",
        "    for x in f:\n",
        "        train_feature.append(x)         \n",
        "    for x in l:\n",
        "        train_label.append(x)\n",
        "    print(len(train_label))\n",
        "\n",
        "    test_feature = []\n",
        "    test_label = []\n",
        "    f,l = get_original_feature_label(patient_path,i,1)\n",
        "    for x in f:\n",
        "        test_feature.append(x)         \n",
        "    for x in l:\n",
        "        test_label.append(x)\n",
        "    print(len(test_label))\n",
        "    \n",
        "    test_feature = np.reshape(test_feature,(np.shape(test_feature)[0],-1))\n",
        "    train_feature = np.reshape(train_feature,(np.shape(train_feature)[0],-1))\n",
        "    acc, auc, f1 = train(train_feature,train_label,test_feature,test_label,i,j)\n",
        "    accl.append(acc)\n",
        "    aucl.append(auc)\n",
        "    f1l.append(f1)\n",
        "    \n",
        "  acc_p.append(np.mean(accl))\n",
        "  auc_p.append(np.mean(aucl))\n",
        "  f1_p.append(np.mean(f1l))"
      ],
      "metadata": {
        "id": "K9Ak-VzQyryU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0944d58-3aef-45da-b562-75fd3c5589fb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "24\n",
            "AUC: 0.9015151515151514\n",
            "96\n",
            "24\n",
            "AUC: 0.9734848484848485\n",
            "96\n",
            "24\n",
            "AUC: 0.9166666666666666\n",
            "96\n",
            "24\n",
            "AUC: 1.0\n",
            "96\n",
            "24\n",
            "AUC: 0.9829545454545454\n",
            "96\n",
            "24\n",
            "AUC: 0.9886363636363638\n",
            "96\n",
            "24\n",
            "AUC: 0.9242424242424242\n",
            "96\n",
            "24\n",
            "AUC: 0.9659090909090908\n",
            "96\n",
            "24\n",
            "AUC: 0.9867424242424243\n",
            "96\n",
            "24\n",
            "AUC: 0.9640151515151515\n",
            "98\n",
            "24\n",
            "AUC: 0.9109848484848485\n",
            "98\n",
            "24\n",
            "AUC: 0.9166666666666665\n",
            "98\n",
            "24\n",
            "AUC: 0.9810606060606061\n",
            "98\n",
            "24\n",
            "AUC: 0.962121212121212\n",
            "98\n",
            "24\n",
            "AUC: 0.9772727272727272\n",
            "97\n",
            "24\n",
            "AUC: 0.8579545454545454\n",
            "97\n",
            "24\n",
            "AUC: 0.9450757575757577\n",
            "97\n",
            "24\n",
            "AUC: 0.9488636363636364\n",
            "97\n",
            "24\n",
            "AUC: 0.8598484848484848\n",
            "97\n",
            "24\n",
            "AUC: 0.9034090909090909\n",
            "96\n",
            "24\n",
            "AUC: 0.9337121212121211\n",
            "96\n",
            "24\n",
            "AUC: 0.9583333333333334\n",
            "96\n",
            "24\n",
            "AUC: 0.9943181818181818\n",
            "96\n",
            "24\n",
            "AUC: 0.9583333333333334\n",
            "97\n",
            "23\n",
            "AUC: 0.9193722943722943\n",
            "97\n",
            "24\n",
            "AUC: 0.9356060606060607\n",
            "97\n",
            "24\n",
            "AUC: 0.9962121212121212\n",
            "97\n",
            "24\n",
            "AUC: 0.9753787878787877\n",
            "97\n",
            "24\n",
            "AUC: 0.9867424242424242\n",
            "97\n",
            "24\n",
            "AUC: 0.9602272727272726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(auc_p)"
      ],
      "metadata": {
        "id": "iDohqSMKvY8Z",
        "outputId": "4d0cd958-b694-4a89-e3d4-2ffeba267ccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9495220057720059"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(acc_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKxpHVXgge4i",
        "outputId": "37d74707-6156-47f7-eb9d-7f323978e509"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7342995169082126"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(f1_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZivhKHOJAP8",
        "outputId": "5a91b287-c034-4e56-ae90-09d88630ed38"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7101190476190476"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiuNK4EkSH7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}