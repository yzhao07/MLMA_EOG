{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "U0NbIApUF-Ob",
        "fAkUcLk8reml",
        "2e1XONqRzhoR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# import"
      ],
      "metadata": {
        "id": "WAV118DIqmML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnyb2GmKmO5W",
        "outputId": "71296784-bf33-494f-8b29-fb5aebfa0215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data')"
      ],
      "metadata": {
        "id": "lGRIirpZqrWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from stroke_probability_map import *"
      ],
      "metadata": {
        "id": "olsnjHc2qsnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from stroke_probability_map_1 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l42EFONcqt11",
        "outputId": "1b4e74f5-99f0-408e-d9be-989d1472cc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data as Data\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "_P-d-YQFq0T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFGndhoMTspy",
        "outputId": "52f213db-e6f4-4227-c384-e55162f0a3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.0\n",
            "  Downloading Levenshtein-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-3.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.0 python-Levenshtein-0.21.0 rapidfuzz-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Levenshtein import ratio"
      ],
      "metadata": {
        "id": "rMLfdj7dUBXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INdrL3EhQ0wf"
      },
      "source": [
        "# File and Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR4iBbuGS_HI"
      },
      "source": [
        "File name:   \n",
        "EOG_00x_xx_xxx.csv:   \n",
        " 00x: participant's ID.    \n",
        " xx:  index of the recording time.    \n",
        " xxx: index of the corresponding eye movements.    \n",
        "      - e.g., xxx is the index of a training word.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EIba5Pg2Zcq"
      },
      "outputs": [],
      "source": [
        "result_path = '/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/Result'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qieqdMYZX17L"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWC2DhqhrkeI"
      },
      "outputs": [],
      "source": [
        "result_path_isolated = '/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Isolated Data/Result'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader"
      ],
      "metadata": {
        "id": "N7Yzrb2rqua_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_labels = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/stroke_labels.npy')"
      ],
      "metadata": {
        "id": "Gi2leL1hFNaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_labels_2 = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/stroke_labels_2.npy')"
      ],
      "metadata": {
        "id": "gpdgwRDCU9kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_labels_16 = np.append(stroke_labels, np.ones((150, 4))*12, axis=1)"
      ],
      "metadata": {
        "id": "43sZtnhQb-Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_labels_3 = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/stroke_labels_3.npy')"
      ],
      "metadata": {
        "id": "gPXJWXayfIUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stroke_labels_4 = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/stroke_labels_4.npy')"
      ],
      "metadata": {
        "id": "3I6xFvHxeAZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, ID_list, R_time_list, model_list, flatten, model_type, s_num, root_dir='/content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous/00'):\n",
        "    self.data = []\n",
        "    self.stroke_probability_map = []\n",
        "    self.label = []\n",
        "    if s_num == 0:\n",
        "      s_labels = stroke_labels\n",
        "    elif s_num == 1:\n",
        "      s_labels = stroke_labels_2\n",
        "    elif s_num == 2:\n",
        "      s_labels = stroke_labels_16\n",
        "    elif s_num == 3:\n",
        "      s_labels = stroke_labels_3\n",
        "    elif s_num == 4:\n",
        "      s_labels = stroke_labels_4\n",
        "\n",
        "    for id_idx in range(len(ID_list)):\n",
        "      file_list = os.listdir(root_dir + str(ID_list[id_idx]) +'/training/')\n",
        "      for f_idx in range(len(file_list)):\n",
        "        if int(file_list[f_idx][8:10]) in R_time_list:\n",
        "          data = pd.read_csv(root_dir + str(ID_list[id_idx]) +'/training/' + file_list[f_idx],  header=None).to_numpy()\n",
        "          #print(data.shape)\n",
        "          data = signal.resample(data, 1024, axis=0)\n",
        "          #print(data.shape)\n",
        "          s = stroke_probability_map_1(data, model_list[id_idx], flatten, model_type)\n",
        "          s = torch.from_numpy(s)\n",
        "          self.stroke_probability_map.append(s)\n",
        "          word_idx = int(file_list[f_idx][-7:-4])-1\n",
        "          self.label.append(torch.from_numpy(s_labels[word_idx]))\n",
        "          data = (data - data.mean(axis=0, keepdims=True))/np.std(data,axis=0, keepdims=True)\n",
        "          data = torch.from_numpy(data)\n",
        "          self.data.append(data)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    return self.data[index].float(), self.stroke_probability_map[index].float(), self.label[index].type(torch.LongTensor)\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "Bw3n2RuarByk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "bKKyfjXOz_kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2+lstm\n",
        "class My_CNN_2_lstm_stroke(nn.Module):\n",
        "  def __init__(self, N=16):\n",
        "    super(My_CNN_2_lstm_stroke, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels=2, out_channels=16, kernel_size=9, padding=5)\n",
        "    nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    nn.init.constant_(self.conv1.bias, 0.0)\n",
        "    self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
        "    self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=3)\n",
        "    nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    nn.init.constant_(self.conv2.bias, 0.0)\n",
        "    self.mp2 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv3.weight)\n",
        "    nn.init.constant_(self.conv3.bias, 0.0)\n",
        "    self.mp3 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv4.weight)\n",
        "    nn.init.constant_(self.conv4.bias, 0.0)\n",
        "    self.amp =  nn.AdaptiveMaxPool1d(N)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=int(3*12+128), hidden_size=25, num_layers=1, batch_first=True, bidirectional=False, dropout=0.5)\n",
        "    for name, param in self.lstm.named_parameters():\n",
        "      if name.startswith(\"weight\"):\n",
        "        nn.init.xavier_normal_(param)\n",
        "      else:\n",
        "        nn.init.zeros_(param)\n",
        "\n",
        "    self.fc1 = nn.Linear(16, 12)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    nn.init.constant_(self.fc1.bias, 0.0)\n",
        "    self.relu4 = nn.LeakyReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    self.fc2 = nn.Linear(25, 13)\n",
        "    nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    nn.init.constant_(self.fc2.bias, 0.0)\n",
        "\n",
        "  def forward(self, x, probability):\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    x = self.relu1(self.mp1(self.conv1(x)))\n",
        "    x = self.relu2(self.mp2(self.conv2(x)))\n",
        "    x = self.relu3(self.mp3(self.conv3(x)))\n",
        "    x = self.conv4(x)\n",
        "    x = self.sigmoid(self.amp(x))\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = torch.cat((x, probability), dim=-1)\n",
        "\n",
        "    x, (_, _) = self.lstm(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.relu4(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8ZBWCDcQ0Au7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5_lstm\n",
        "class My_CNN_5_lstm_stroke(nn.Module):\n",
        "  def __init__(self, N=16):\n",
        "    super(My_CNN_5_lstm_stroke, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=9, padding=5)\n",
        "    nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    nn.init.constant_(self.conv1.bias, 0.0)\n",
        "    self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
        "    self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=3)\n",
        "    nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    nn.init.constant_(self.conv2.bias, 0.0)\n",
        "    self.mp2 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv3.weight)\n",
        "    nn.init.constant_(self.conv3.bias, 0.0)\n",
        "    self.mp3 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv4 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv4.weight)\n",
        "    nn.init.constant_(self.conv4.bias, 0.0)\n",
        "    self.amp =  nn.AdaptiveMaxPool1d(N)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=int(3*12+512), hidden_size=50, num_layers=1, batch_first=True, bidirectional=False, dropout=0.5)\n",
        "    for name, param in self.lstm.named_parameters():\n",
        "      if name.startswith(\"weight\"):\n",
        "        nn.init.xavier_normal_(param)\n",
        "      else:\n",
        "        nn.init.zeros_(param)\n",
        "\n",
        "    self.fc1 = nn.Linear(16, 16)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    nn.init.constant_(self.fc1.bias, 0.0)\n",
        "    self.relu4 = nn.LeakyReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    self.fc2 = nn.Linear(50, 13)\n",
        "    nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    nn.init.constant_(self.fc2.bias, 0.0)\n",
        "\n",
        "  def forward(self, x, probability):\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    x = self.relu1(self.mp1(self.conv1(x)))\n",
        "    x = self.relu2(self.mp2(self.conv2(x)))\n",
        "    x = self.relu3(self.mp3(self.conv3(x)))\n",
        "    x = self.conv4(x)\n",
        "    x = self.sigmoid(self.amp(x))\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = torch.cat((x, probability), dim=-1)\n",
        "\n",
        "    x, (_, _) = self.lstm(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.relu4(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "JRVBUXj5eaPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4_lstm\n",
        "class My_CNN_4_lstm_stroke(nn.Module):\n",
        "  def __init__(self, N=16):\n",
        "    super(My_CNN_4_lstm_stroke, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=9, padding=5)\n",
        "    nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    nn.init.constant_(self.conv1.bias, 0.0)\n",
        "    self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
        "    self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=3)\n",
        "    nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    nn.init.constant_(self.conv2.bias, 0.0)\n",
        "    self.mp2 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv3.weight)\n",
        "    nn.init.constant_(self.conv3.bias, 0.0)\n",
        "    self.mp3 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv4 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv4.weight)\n",
        "    nn.init.constant_(self.conv4.bias, 0.0)\n",
        "    self.amp =  nn.AdaptiveMaxPool1d(N)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=int(3*12+256), hidden_size=50, num_layers=1, batch_first=True, bidirectional=False, dropout=0.5)\n",
        "    for name, param in self.lstm.named_parameters():\n",
        "      if name.startswith(\"weight\"):\n",
        "        nn.init.xavier_normal_(param)\n",
        "      else:\n",
        "        nn.init.zeros_(param)\n",
        "\n",
        "    self.fc1 = nn.Linear(16, 16)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    nn.init.constant_(self.fc1.bias, 0.0)\n",
        "    self.relu4 = nn.LeakyReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    self.fc2 = nn.Linear(50, 13)\n",
        "    nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    nn.init.constant_(self.fc2.bias, 0.0)\n",
        "\n",
        "  def forward(self, x, probability):\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    x = self.relu1(self.mp1(self.conv1(x)))\n",
        "    x = self.relu2(self.mp2(self.conv2(x)))\n",
        "    x = self.relu3(self.mp3(self.conv3(x)))\n",
        "    x = self.conv4(x)\n",
        "    x = self.sigmoid(self.amp(x))\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = torch.cat((x, probability), dim=-1)\n",
        "\n",
        "    x, (_, _) = self.lstm(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.relu4(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "DRBpR0i-ZzKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3_lstm\n",
        "class My_CNN_3_lstm_stroke(nn.Module):\n",
        "  def __init__(self, N=16):\n",
        "    super(My_CNN_3_lstm_stroke, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=9, padding=5)\n",
        "    nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    nn.init.constant_(self.conv1.bias, 0.0)\n",
        "    self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
        "    self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=3)\n",
        "    nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    nn.init.constant_(self.conv2.bias, 0.0)\n",
        "    self.mp2 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv3.weight)\n",
        "    nn.init.constant_(self.conv3.bias, 0.0)\n",
        "    self.mp3 = nn.MaxPool1d(kernel_size=2)\n",
        "    self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
        "    nn.init.xavier_uniform_(self.conv4.weight)\n",
        "    nn.init.constant_(self.conv4.bias, 0.0)\n",
        "    self.amp =  nn.AdaptiveMaxPool1d(N)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=int(3*12+256), hidden_size=25, num_layers=1, batch_first=True, bidirectional=False, dropout=0.5)\n",
        "    for name, param in self.lstm.named_parameters():\n",
        "      if name.startswith(\"weight\"):\n",
        "        nn.init.xavier_normal_(param)\n",
        "      else:\n",
        "        nn.init.zeros_(param)\n",
        "\n",
        "    self.fc1 = nn.Linear(16, 12)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    nn.init.constant_(self.fc1.bias, 0.0)\n",
        "    self.relu4 = nn.LeakyReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    self.fc2 = nn.Linear(25, 13)\n",
        "    nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    nn.init.constant_(self.fc2.bias, 0.0)\n",
        "\n",
        "  def forward(self, x, probability):\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    x = self.relu1(self.mp1(self.conv1(x)))\n",
        "    x = self.relu2(self.mp2(self.conv2(x)))\n",
        "    x = self.relu3(self.mp3(self.conv3(x)))\n",
        "    x = self.conv4(x)\n",
        "    x = self.sigmoid(self.amp(x))\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = torch.cat((x, probability), dim=-1)\n",
        "\n",
        "    x, (_, _) = self.lstm(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.relu4(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = torch.transpose(x, -1, -2)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "C_pJ5QVdQlGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross entropy:\n",
        "\n",
        "input N,C,..."
      ],
      "metadata": {
        "id": "qK6Q83ZJ6rMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Functions"
      ],
      "metadata": {
        "id": "6IHL-CEU6xtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_model(model,epochs,optmizer,criterion, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    x = 0\n",
        "    for batch_idx, (data, probability, label) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        probability = probability.to(device)\n",
        "        optmizer.zero_grad()  \n",
        "        output = model(data, probability)\n",
        "        # print(type(output), type(label))\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optmizer.step() \n",
        "        train_loss.append(loss.item()) \n",
        "        #if(batch_idx+1)%3 == 0:\n",
        "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.\\\n",
        "                #format(epochs, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return np.mean(train_loss), model"
      ],
      "metadata": {
        "id": "mfj4c0327GX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle(x):\n",
        "  return_list = [x[0]]\n",
        "  x = np.append(x, np.ones((1,))*-1, axis=0)\n",
        "  for i in range(1, x.shape[0]-1):\n",
        "    if x[i] != x[i-1]:\n",
        "      return_list.append(x[i])\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "TqWREXzZ9azg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_list(y_true, y_pred):\n",
        "  return accuracy_score(y_true, y_pred), \\\n",
        "  f1_score(y_true, y_pred, average='micro', zero_division=0), f1_score(y_true, y_pred, average='macro', zero_division=0), \\\n",
        "  precision_score(y_true, y_pred, average='micro', zero_division=0), precision_score(y_true, y_pred, average='macro', zero_division=0), \\\n",
        "  recall_score(y_true, y_pred, average='micro', zero_division=0), recall_score(y_true, y_pred, average='macro', zero_division=0)"
      ],
      "metadata": {
        "id": "tCZnbibLcimg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,epochs,criterion, dataloader, T_T='Test'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    c = 0\n",
        "    y_pred_prob = np.zeros((0, 13, 16))\n",
        "    y_true = np.zeros((0, 16))\n",
        "    s_f = nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        for data, probability, label in dataloader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            probability = probability.to(device)\n",
        "            output = model(data, probability)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            output = s_f(output)\n",
        "            y_pred_prob = np.append(y_pred_prob, output.cpu(), axis=0)\n",
        "            y_true = np.append(y_true, label.cpu(), axis=0)\n",
        "            c += 1\n",
        "    test_loss /= c\n",
        "    if epochs%50 == 0:\n",
        "        print('EPOCH:{}    {} set: Average loss: {:.4f}'.format(epochs, T_T, test_loss))\n",
        "\n",
        "    y_pred = y_pred_prob.argmax(axis=1)\n",
        "    y_pred_gram = np.zeros(y_pred.shape)\n",
        "\n",
        "    r = 0\n",
        "    r_rle = 0\n",
        "    r_gram = 0\n",
        "    r_rle_gram = 0\n",
        "    for i in range(y_pred.shape[0]):\n",
        "      idx = np.where(y_pred[i] != 12)\n",
        "      s1 = y_pred[i][idx]\n",
        "      idx = np.where(y_true[i] != 12)\n",
        "      s2 = y_true[i][idx]\n",
        "      r+=ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      s2 = rle(s2)\n",
        "      r_rle+=ratio(s1, s2)\n",
        "\n",
        "      s1_gram = [int(y_pred_prob[i, :-1, 0].argmax())]\n",
        "      for j in range(1, 16):\n",
        "        prob_ = np.multiply(y_pred_prob[i, :, j], gram_1[s1_gram[-1]])\n",
        "        s1_gram.append(int(prob_.argmax()))\n",
        "      s1_gram = np.array(s1_gram)\n",
        "      y_pred_gram[i] = s1_gram\n",
        "      idx = np.where(s1_gram != 12)\n",
        "      s1 = s1_gram[idx]    \n",
        "      idx = np.where(y_true[i] != 12)\n",
        "      s2 = y_true[i][idx]\n",
        "      r_gram += ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      s2 = rle(s2)\n",
        "      r_rle_gram += ratio(s1, s2)  \n",
        "\n",
        "    r_rle = r_rle/y_pred.shape[0]\n",
        "    r = r/y_pred.shape[0]\n",
        "    r_rle_gram = r_rle_gram/y_pred.shape[0]\n",
        "    r_gram = r_gram/y_pred.shape[0]\n",
        "\n",
        "    y_pred = y_pred.reshape((-1))\n",
        "    y_pred_gram = y_pred_gram.reshape((-1))\n",
        "    y_true = y_true.reshape((-1))\n",
        "\n",
        "    return_array = np.zeros((1+4+7*2))\n",
        "    return_array[0] = test_loss\n",
        "    return_array[1:5] = r, r_rle, r_gram, r_rle_gram\n",
        "    return_array[5:(5+7)] = score_list(y_true, y_pred)\n",
        "    return_array[(5+7):] = score_list(y_true, y_pred_gram)\n",
        "    return return_array"
      ],
      "metadata": {
        "id": "AMKt30Mb7IR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_gram(model,epochs,criterion, dataloader, T_T='Test'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    c = 0\n",
        "    y_pred_prob = np.zeros((0, 13, 16))\n",
        "    y_true = np.zeros((0, 16))\n",
        "    s_f = nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        for data, probability, label in dataloader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            probability = probability.to(device)\n",
        "            output = model(data, probability)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            output = s_f(output)\n",
        "            y_pred_prob = np.append(y_pred_prob, output.cpu(), axis=0)\n",
        "            y_true = np.append(y_true, label.cpu(), axis=0)\n",
        "            c += 1\n",
        "    test_loss /= c\n",
        "    if epochs%50 == 0:\n",
        "        print('EPOCH:{}    {} set: Average loss: {:.4f}'.format(epochs, T_T, test_loss))\n",
        "\n",
        "    y_pred = y_pred_prob.argmax(axis=1)\n",
        "\n",
        "    r = np.zeros((4,))\n",
        "    r_rle = np.zeros((4,))\n",
        "    for i in range(y_pred.shape[0]):\n",
        "      # no gram\n",
        "      idx_12 = np.where(y_pred[i][1:] == 12)\n",
        "      if len(idx_12[0]) > 0:\n",
        "        idx = int(idx_12[0][0])\n",
        "        s1 = y_pred[i][:(idx+1)]\n",
        "      else:\n",
        "        s1 = y_pred[i]\n",
        "      idx = int(np.where(y_true[i]==12)[0][0])\n",
        "      s2 = y_true[i][:idx]\n",
        "      r[0]+=ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      s2_rle = rle(s2)\n",
        "      r_rle[0]+=ratio(s1, s2_rle)\n",
        "\n",
        "      # gram 1\n",
        "      s1_gram = [int(y_pred_prob[i, :-1, 0].argmax())]\n",
        "      for j in range(1, 16):\n",
        "        prob_ = np.multiply(y_pred_prob[i, :, j], gram_1[s1_gram[-1]])\n",
        "        if int(prob_.argmax()) == 12:\n",
        "          break\n",
        "        s1_gram.append(int(prob_.argmax()))\n",
        "      s1 = np.array(s1_gram)   \n",
        "      r[1] += ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      r_rle[1] += ratio(s1, s2_rle)  \n",
        "\n",
        "      # gram 2\n",
        "      s1_gram = [int(y_pred_prob[i, :-1, 0].argmax()), int(y_pred_prob[i, :-1, 1].argmax())]\n",
        "      for j in range(2, 16):\n",
        "        prob_ = np.multiply(y_pred_prob[i, :, j], gram_2[s1_gram[-2], s1_gram[-1]])\n",
        "        if int(prob_.argmax()) == 12:\n",
        "          break\n",
        "        s1_gram.append(int(prob_.argmax()))\n",
        "      s1 = np.array(s1_gram)   \n",
        "      r[2] += ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      r_rle[2] += ratio(s1, s2_rle) \n",
        "\n",
        "      # gram 3\n",
        "      s1_gram = [int(y_pred_prob[i, :-1, 0].argmax()), int(y_pred_prob[i, :-1, 1].argmax()), int(y_pred_prob[i, :-1, 2].argmax())]\n",
        "      for j in range(3, 16):\n",
        "        prob_ = np.multiply(y_pred_prob[i, :, j], gram_3[s1_gram[-3], s1_gram[-2], s1_gram[-1]])\n",
        "        if int(prob_.argmax()) == 12:\n",
        "          break\n",
        "        s1_gram.append(int(prob_.argmax()))\n",
        "      s1 = np.array(s1_gram)   \n",
        "      r[3] += ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      r_rle[3] += ratio(s1, s2_rle)  \n",
        "\n",
        "    r_rle = r_rle/y_pred.shape[0]\n",
        "    r = r/y_pred.shape[0]\n",
        "    return np.append(np.ones((1,))*test_loss, np.append(r, r_rle, axis=0), axis=0)"
      ],
      "metadata": {
        "id": "SFonODTbwmTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,epochs,criterion, dataloader, T_T='Test'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    c = 0\n",
        "    y_pred_prob = np.zeros((0, 13, 16))\n",
        "    y_true = np.zeros((0, 16))\n",
        "    s_f = nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        for data, probability, label in dataloader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            probability = probability.to(device)\n",
        "            output = model(data, probability)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            output = s_f(output)\n",
        "            y_pred_prob = np.append(y_pred_prob, output.cpu(), axis=0)\n",
        "            y_true = np.append(y_true, label.cpu(), axis=0)\n",
        "            c += 1\n",
        "    test_loss /= c\n",
        "    if epochs%50 == 0:\n",
        "        print('EPOCH:{}    {} set: Average loss: {:.4f}'.format(epochs, T_T, test_loss))\n",
        "\n",
        "    y_pred = y_pred_prob.argmax(axis=1)\n",
        "    y_pred_gram = np.zeros(y_pred.shape)\n",
        "\n",
        "    r = 0\n",
        "    r_rle = 0\n",
        "    r_gram = 0\n",
        "    r_rle_gram = 0\n",
        "    for i in range(y_pred.shape[0]):\n",
        "      idx = np.where(y_pred[i] != 12)\n",
        "      s1 = y_pred[i][idx]\n",
        "      idx = np.where(y_true[i] != 12)\n",
        "      s2 = y_true[i][idx]\n",
        "      r+=ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      s2 = rle(s2)\n",
        "      r_rle+=ratio(s1, s2)\n",
        "\n",
        "      s1_gram = [int(y_pred_prob[i, :-1, 0].argmax())]\n",
        "      for j in range(1, 16):\n",
        "        prob_ = np.multiply(y_pred_prob[i, :, j], gram_1[s1_gram[-1]])\n",
        "        s1_gram.append(int(prob_.argmax()))\n",
        "      s1_gram = np.array(s1_gram)\n",
        "      y_pred_gram[i] = s1_gram\n",
        "      idx = np.where(s1_gram != 12)\n",
        "      s1 = s1_gram[idx]    \n",
        "      idx = np.where(y_true[i] != 12)\n",
        "      s2 = y_true[i][idx]\n",
        "      r_gram += ratio(s1, s2)\n",
        "      s1 = rle(s1)\n",
        "      s2 = rle(s2)\n",
        "      r_rle_gram += ratio(s1, s2)  \n",
        "\n",
        "    r_rle = r_rle/y_pred.shape[0]\n",
        "    r = r/y_pred.shape[0]\n",
        "    r_rle_gram = r_rle_gram/y_pred.shape[0]\n",
        "    r_gram = r_gram/y_pred.shape[0]\n",
        "\n",
        "    y_pred = y_pred.reshape((-1))\n",
        "    y_pred_gram = y_pred_gram.reshape((-1))\n",
        "    y_true = y_true.reshape((-1))\n",
        "\n",
        "    return_array = np.zeros((1+4+7*2))\n",
        "    return_array[0] = test_loss\n",
        "    return_array[1:5] = r, r_rle, r_gram, r_rle_gram\n",
        "    return_array[5:(5+7)] = score_list(y_true, y_pred)\n",
        "    return_array[(5+7):] = score_list(y_true, y_pred_gram)\n",
        "    return return_array"
      ],
      "metadata": {
        "id": "5tcE6XcywQjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_num = np.zeros((13))\n",
        "for i in range(0, 13):\n",
        "    class_num[i] = np.sum(stroke_labels_16==i)\n",
        "print(class_num)\n",
        "weights = np.sum(class_num)/(class_num*13)\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbml-Y3sIfW4",
        "outputId": "4d12ded1-32c6-4c32-d4f3-4dae60ea1f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 132.   94.  167.  135.   25.  113.   29.   15.   71.   43.   34.   61.\n",
            " 1481.]\n",
            "[ 1.3986014   1.96399345  1.10548135  1.36752137  7.38461538  1.63376447\n",
            "  6.36604775 12.30769231  2.60021668  4.29338104  5.42986425  3.02648172\n",
            "  0.1246559 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main_function(total_epoch=100, dataloader_list=None, model_para=None, model_save=False, model_name=None, cross_val=True, weight_decay=1e-3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = My_CNN_5_lstm_stroke().to(device)\n",
        "        \n",
        "    optmizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=weight_decay)  \n",
        "    #optmizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=weight_decay) \n",
        "    scheduler = lr_scheduler.StepLR(optmizer, step_size=50, gamma=0.5, verbose=False) \n",
        "    weight=torch.tensor(weights).to(device).float()\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight).to(device)  \n",
        "    \n",
        "    train_loss = np.zeros((total_epoch))\n",
        "    score = np.zeros((len(dataloader_list), 8+1, total_epoch)) # loss, ratio, accuracy, f1 score*2, precision*2, recall*2\n",
        "    \n",
        "    for i in tqdm(range(total_epoch)):\n",
        "        train_loss[i], model = Train_model(model, i, optmizer, criterion, dataloader_list[0])\n",
        "        scheduler.step()\n",
        "        for j in range(len(dataloader_list)):\n",
        "            if j == 0:\n",
        "                T_T = 'Train'\n",
        "            elif j == 1:\n",
        "                T_T = 'Validation'\n",
        "            else:\n",
        "                T_T = 'Test'\n",
        "            score[j, :, i] = test_with_gram(model, i, criterion, dataloader_list[j], T_T=T_T)\n",
        "        #if np.argmin(score[1, 0, :(i+1)]) == i:\n",
        "            #if model_save:\n",
        "                #torch.save(model.state_dict(), model_name)     \n",
        "    #if model_save: \n",
        "        #np.savez(model_name[:-4], train_loss=train_loss, score=score)\n",
        "    if model_save:\n",
        "      torch.save(model.state_dict(), model_name)\n",
        "    if cross_val:\n",
        "        epoch_best = np.argmin(score[1, 0, :])\n",
        "        return score[:, :, epoch_best]\n",
        "    else:\n",
        "        return train_loss, score"
      ],
      "metadata": {
        "id": "vyw3cB1_Egta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leave one trial out"
      ],
      "metadata": {
        "id": "U0NbIApUF-Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "save_number = 0\n",
        "s_num = 0\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 9))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=300, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('fold{} Train Loss{}, Train Acc{} ratio{}'.format(fold_idx, score[fold_idx-1, 0, 0], score[fold_idx-1, 0, 1], score[fold_idx-1, 0, 2]))\n",
        "    print('fold{} Val Loss{}, Val Acc{} ratio{}'.format(fold_idx, score[fold_idx-1, 1, 0], score[fold_idx-1, 1, 1], score[fold_idx-1, 1, 2]))\n",
        "    print('fold{} Test Loss{}, Test Acc{} ratio{}'.format(fold_idx, score[fold_idx-1, 2, 0], score[fold_idx-1, 2, 1], score[fold_idx-1, 2, 2]))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0420_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuAkkPO7GC8J",
        "outputId": "0bc94056-b2a3-4a6a-f525-1ca6924254dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4969\n",
            "EPOCH:0    Validation set: Average loss: 2.4969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<02:55,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.4949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:28<02:22,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 1.2136\n",
            "EPOCH:50    Validation set: Average loss: 1.3157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:29<02:22,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [00:57<01:54,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.9310\n",
            "EPOCH:100    Validation set: Average loss: 1.2099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [00:58<01:54,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 1.2067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:26<01:26,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.8101\n",
            "EPOCH:150    Validation set: Average loss: 1.2269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:27<01:25,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 1.2086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [01:55<00:57,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.7594\n",
            "EPOCH:200    Validation set: Average loss: 1.2829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [01:56<00:57,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 1.2496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:24<00:29,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.7307\n",
            "EPOCH:250    Validation set: Average loss: 1.3028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:24<00:28,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.2624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:53<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold1 Train Loss0.9563578963279724, Train Acc0.5901131216217969 ratio0.6956932261208577\n",
            "fold1 Val Loss1.1949436143040657, Val Acc0.5425397775408118 ratio0.6558333333333334\n",
            "fold1 Test Loss1.1980936080217361, Test Acc0.5476954103210583 ratio0.6554629629629629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5296\n",
            "EPOCH:0    Validation set: Average loss: 2.5318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<02:56,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:29<02:26,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 1.1443\n",
            "EPOCH:50    Validation set: Average loss: 1.2883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:29<02:25,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.2377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [00:58<01:56,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.8223\n",
            "EPOCH:100    Validation set: Average loss: 1.1673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [00:58<01:56,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 1.1246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:27<01:28,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.6979\n",
            "EPOCH:150    Validation set: Average loss: 1.1969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:28<01:27,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 1.1418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [01:56<00:59,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.6366\n",
            "EPOCH:200    Validation set: Average loss: 1.2524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [01:57<00:59,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 1.2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:26<00:29,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.6075\n",
            "EPOCH:250    Validation set: Average loss: 1.2747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:26<00:28,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.2289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:55<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold2 Train Loss0.7924333864992316, Train Acc0.6611498740621602 ratio0.7291057504873294\n",
            "fold2 Val Loss1.1626117676496506, Val Acc0.5985505336405771 ratio0.6712962962962963\n",
            "fold2 Test Loss1.1145462021231651, Test Acc0.5991526645200557 ratio0.6751851851851852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5293\n",
            "EPOCH:0    Validation set: Average loss: 2.5376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:12,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:29<02:26,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 1.0498\n",
            "EPOCH:50    Validation set: Average loss: 1.1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:30<02:26,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.1876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [00:59<01:58,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.7778\n",
            "EPOCH:100    Validation set: Average loss: 1.0975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:00<01:59,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 1.1116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:29<01:31,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.6619\n",
            "EPOCH:150    Validation set: Average loss: 1.1150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:30<01:30,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 1.1118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [01:59<01:03,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.6110\n",
            "EPOCH:200    Validation set: Average loss: 1.1449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:00<01:02,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 1.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:29<00:29,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.5846\n",
            "EPOCH:250    Validation set: Average loss: 1.1684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:30<00:29,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.1645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:59<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold3 Train Loss0.7683521563356573, Train Acc0.655074190570928 ratio0.7450066983315066\n",
            "fold3 Val Loss1.0738461315631866, Val Acc0.5964544452281108 ratio0.6974416017797553\n",
            "fold3 Test Loss1.076750673353672, Test Acc0.5994593594209203 ratio0.6964814814814815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5072\n",
            "EPOCH:0    Validation set: Average loss: 2.5099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:11,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:30<02:34,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 1.3455\n",
            "EPOCH:50    Validation set: Average loss: 1.4182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:30<02:34,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.3898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:00<02:02,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.9987\n",
            "EPOCH:100    Validation set: Average loss: 1.2716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:01<02:01,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 1.2131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:30<01:28,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.8570\n",
            "EPOCH:150    Validation set: Average loss: 1.3135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:30<01:28,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 1.2018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:00<00:59,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.7929\n",
            "EPOCH:200    Validation set: Average loss: 1.3219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:00<00:58,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 1.2034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:29<00:29,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.7608\n",
            "EPOCH:250    Validation set: Average loss: 1.3843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:30<00:29,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:59<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold4 Train Loss1.053864443844015, Train Acc0.5814108372494451 ratio0.6845868321771936\n",
            "fold4 Val Loss1.248142696917057, Val Acc0.5521316409688093 ratio0.6505196733481812\n",
            "fold4 Test Loss1.2399060726165771, Test Acc0.5386330424479997 ratio0.64293659621802\n",
            "Train [0.89275197 0.62193701 0.71359813 0.71359813 0.6042101  0.71359813\n",
            " 0.56201444 0.71359813 0.73137049]\n",
            "Val [1.16988605 0.5724191  0.66877273 0.66877273 0.51889779 0.66877273\n",
            " 0.48890727 0.66877273 0.61318907]\n",
            "Test [1.15732414 0.57123512 0.66751656 0.66751656 0.51951108 0.66751656\n",
            " 0.48926736 0.66751656 0.61420537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 1\n",
        "s_num = 2\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 9))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=300, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('fold{} Train Loss{}, Train ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 0, 0], score[fold_idx-1, 0, 1], score[fold_idx-1, 0, 2]))\n",
        "    print('fold{} Val Loss{}, Val ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 1, 0], score[fold_idx-1, 1, 1], score[fold_idx-1, 1, 2]))\n",
        "    print('fold{} Test Loss{}, Test ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 2, 0], score[fold_idx-1, 2, 1], score[fold_idx-1, 2, 2]))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0420_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaSrdptvcdlM",
        "outputId": "ce898744-506e-454c-db4e-da7bb9d9604e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4550\n",
            "EPOCH:0    Validation set: Average loss: 2.4553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:10,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.4606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:31<02:35,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.9755\n",
            "EPOCH:50    Validation set: Average loss: 1.1363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:31<02:34,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.1455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:02<02:06,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.6432\n",
            "EPOCH:100    Validation set: Average loss: 1.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:03<02:06,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 1.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:34<01:34,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.4987\n",
            "EPOCH:150    Validation set: Average loss: 1.0759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:34<01:33,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 1.0432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:05<01:02,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.4349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:05<01:01,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Validation set: Average loss: 1.1186\n",
            "EPOCH:200    Test set: Average loss: 1.0724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:36<00:31,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.4068\n",
            "EPOCH:250    Validation set: Average loss: 1.1536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:37<00:30,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:07<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold1 Train Loss0.652546920559623, Train Acc0.6401078960272532 ratio0.7822322733918129\n",
            "fold1 Val Loss1.0206185653805733, Val Acc0.5665300731642344 ratio0.7361805555555555\n",
            "fold1 Test Loss1.0118003636598587, Test Acc0.5702674863931337 ratio0.736875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:28,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Validation set: Average loss: 2.4923\n",
            "EPOCH:0    Test set: Average loss: 2.4923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:32<02:41,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8674\n",
            "EPOCH:50    Validation set: Average loss: 1.0483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:33<02:41,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.0367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:04<02:07,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.5366\n",
            "EPOCH:100    Validation set: Average loss: 0.9339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:05<02:07,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:36<01:34,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.4086\n",
            "EPOCH:150    Validation set: Average loss: 0.9783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:37<01:34,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.9290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:08<01:04,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.3470\n",
            "EPOCH:200    Validation set: Average loss: 1.0296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:09<01:04,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 0.9647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:41<00:32,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.3183\n",
            "EPOCH:250    Validation set: Average loss: 1.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:41<00:31,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 1.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:13<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold2 Train Loss0.5340991832993247, Train Acc0.7306342966141292 ratio0.8448921783625731\n",
            "fold2 Val Loss0.9283766895532608, Val Acc0.6459854107498597 ratio0.7973611111111111\n",
            "fold2 Test Loss0.9007765538990498, Test Acc0.6462686495650899 ratio0.79625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:29,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Validation set: Average loss: 2.5139\n",
            "EPOCH:0    Test set: Average loss: 2.5105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:32<02:41,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.6224\n",
            "EPOCH:50    Validation set: Average loss: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:32<02:41,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.8391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:04<02:08,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3586\n",
            "EPOCH:100    Validation set: Average loss: 0.7361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:05<02:07,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.7725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:36<01:35,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2596\n",
            "EPOCH:150    Validation set: Average loss: 0.8138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:36<01:35,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:08<01:02,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.2167\n",
            "EPOCH:200    Validation set: Average loss: 0.8645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:08<01:02,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 0.8892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:39<00:32,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.1949\n",
            "EPOCH:250    Validation set: Average loss: 0.9065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:40<00:31,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 0.9302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:12<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold3 Train Loss0.4287009740417654, Train Acc0.7630373026664088 ratio0.8652950310559007\n",
            "fold3 Val Loss0.7356007322669029, Val Acc0.6945721786793045 ratio0.8206340378197998\n",
            "fold3 Test Loss0.7707182243466377, Test Acc0.6944173966441768 ratio0.8234027777777778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4949\n",
            "EPOCH:0    Validation set: Average loss: 2.4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/300 [00:00<03:27,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:31<02:39,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8440\n",
            "EPOCH:50    Validation set: Average loss: 1.0213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 51/300 [00:32<02:38,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:04<02:07,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4668\n",
            "EPOCH:100    Validation set: Average loss: 0.8763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:04<02:06,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [01:36<01:37,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3288\n",
            "EPOCH:150    Validation set: Average loss: 0.8972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 151/300 [01:36<01:37,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:08<01:03,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.2705\n",
            "EPOCH:200    Validation set: Average loss: 0.9857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 201/300 [02:08<01:03,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Test set: Average loss: 0.9327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [02:40<00:31,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.2451\n",
            "EPOCH:250    Validation set: Average loss: 1.0369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 251/300 [02:40<00:31,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Test set: Average loss: 0.9833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:12<00:00,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold4 Train Loss0.402866546403278, Train Acc0.7806729885412748 ratio0.8683598028477546\n",
            "fold4 Val Loss0.8726288825273514, Val Acc0.6731424747226127 ratio0.8030345211581291\n",
            "fold4 Test Loss0.848213717341423, Test Acc0.6682150750481759 ratio0.8043659621802002\n",
            "Train [0.50455341 0.72861312 0.84019482 0.84019482 0.74797939 0.84019482\n",
            " 0.69359006 0.84019482 0.84837378]\n",
            "Val [0.88930622 0.64505753 0.78930256 0.78930256 0.62626588 0.78930256\n",
            " 0.58678697 0.78930256 0.69870364]\n",
            "Test [0.88287721 0.64479215 0.79022343 0.79022343 0.6254642  0.79022343\n",
            " 0.58532724 0.79022343 0.6986299 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 2\n",
        "s_num = 2\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 10))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=300, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('fold{} Train Loss{}, Train ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 0, 0], score[fold_idx-1, 0, 1], score[fold_idx-1, 0, 2]))\n",
        "    print('fold{} Val Loss{}, Val ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 1, 0], score[fold_idx-1, 1, 1], score[fold_idx-1, 1, 2]))\n",
        "    print('fold{} Test Loss{}, Test ratio{} Acc{}'.format(fold_idx, score[fold_idx-1, 2, 0], score[fold_idx-1, 2, 1], score[fold_idx-1, 2, 2]))\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0420_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI2Cg757gjfL",
        "outputId": "2c34f369-16cc-4970-c2d0-f5c7a36adc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5294\n",
            "EPOCH:0    Validation set: Average loss: 2.5287\n",
            "EPOCH:0    Test set: Average loss: 2.5315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:47<03:33,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.6925\n",
            "EPOCH:50    Validation set: Average loss: 0.8860\n",
            "EPOCH:50    Test set: Average loss: 0.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:30<02:49,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 101/300 [01:31<02:51,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Validation set: Average loss: 0.8894\n",
            "EPOCH:100    Test set: Average loss: 0.8886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [02:13<02:09,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2586\n",
            "EPOCH:150    Validation set: Average loss: 0.9839\n",
            "EPOCH:150    Test set: Average loss: 0.9625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:56<01:25,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.2062\n",
            "EPOCH:200    Validation set: Average loss: 1.0494\n",
            "EPOCH:200    Test set: Average loss: 1.0388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [03:38<00:42,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.1824\n",
            "EPOCH:250    Validation set: Average loss: 1.1244\n",
            "EPOCH:250    Test set: Average loss: 1.1166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:21<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold1 Train Loss0.4028020623055371, Train ratio0.7452614006134127 Acc0.838327161898839\n",
            "fold1 Val Loss0.8125630877912045, Val ratio0.6717098155160593 Acc0.7601820683043604\n",
            "fold1 Test Loss0.8345514982938766, Test ratio0.6648649947308367 Acc0.7590922958668062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4889\n",
            "EPOCH:0    Validation set: Average loss: 2.4768\n",
            "EPOCH:0    Test set: Average loss: 2.4900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:44<03:45,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.6721\n",
            "EPOCH:50    Validation set: Average loss: 0.9036\n",
            "EPOCH:50    Test set: Average loss: 0.8803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:29<02:59,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3425\n",
            "EPOCH:100    Validation set: Average loss: 0.8585\n",
            "EPOCH:100    Test set: Average loss: 0.8133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [02:14<02:11,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2082\n",
            "EPOCH:150    Validation set: Average loss: 0.9418\n",
            "EPOCH:150    Test set: Average loss: 0.8747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [02:58<01:28,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.1581\n",
            "EPOCH:200    Validation set: Average loss: 1.0227\n",
            "EPOCH:200    Test set: Average loss: 0.9502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [03:43<00:44,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.1335\n",
            "EPOCH:250    Validation set: Average loss: 1.0833\n",
            "EPOCH:250    Test set: Average loss: 0.9925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:27<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold2 Train Loss0.3695053227923133, Train ratio0.7843179499361623 Acc0.8474429235159081\n",
            "fold2 Val Loss0.8368771336972713, Val ratio0.6795158299637156 Acc0.7419325084864298\n",
            "fold2 Test Loss0.8125982284545898, Test ratio0.6822816397759647 Acc0.7460784804481916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5037\n",
            "EPOCH:0    Validation set: Average loss: 2.5036\n",
            "EPOCH:0    Test set: Average loss: 2.5025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:45<03:46,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8412\n",
            "EPOCH:50    Validation set: Average loss: 0.9883\n",
            "EPOCH:50    Test set: Average loss: 1.0146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:30<03:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4837\n",
            "EPOCH:100    Validation set: Average loss: 0.8833\n",
            "EPOCH:100    Test set: Average loss: 0.9273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [02:15<02:13,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3462\n",
            "EPOCH:150    Validation set: Average loss: 0.9289\n",
            "EPOCH:150    Test set: Average loss: 0.9806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [03:00<01:29,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.2849\n",
            "EPOCH:200    Validation set: Average loss: 0.9901\n",
            "EPOCH:200    Test set: Average loss: 1.0391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [03:45<00:44,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.2523\n",
            "EPOCH:250    Validation set: Average loss: 1.0570\n",
            "EPOCH:250    Test set: Average loss: 1.1067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:31<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold3 Train Loss0.5212844786318865, Train ratio0.723185272506889 Acc0.8052556161077354\n",
            "fold3 Val Loss0.8713243715465069, Val ratio0.6485205964575039 Acc0.7225346948339836\n",
            "fold3 Test Loss0.9268290773034096, Test ratio0.6419444176967412 Acc0.7178176620803041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5089\n",
            "EPOCH:0    Validation set: Average loss: 2.5094\n",
            "EPOCH:0    Test set: Average loss: 2.5123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 50/300 [00:46<03:57,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.9635\n",
            "EPOCH:50    Validation set: Average loss: 1.1353\n",
            "EPOCH:50    Test set: Average loss: 1.1296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 100/300 [01:33<03:07,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.5269\n",
            "EPOCH:100    Validation set: Average loss: 0.9003\n",
            "EPOCH:100    Test set: Average loss: 0.8848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 150/300 [02:19<02:15,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3651\n",
            "EPOCH:150    Validation set: Average loss: 1.0219\n",
            "EPOCH:150    Test set: Average loss: 0.9281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 200/300 [03:04<01:30,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:200    Train set: Average loss: 0.2932\n",
            "EPOCH:200    Validation set: Average loss: 1.0881\n",
            "EPOCH:200    Test set: Average loss: 1.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 250/300 [03:46<00:37,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:250    Train set: Average loss: 0.2622\n",
            "EPOCH:250    Validation set: Average loss: 1.1535\n",
            "EPOCH:250    Test set: Average loss: 1.0428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:30<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold4 Train Loss0.5268813791600141, Train ratio0.728257159655363 Acc0.7964331926064578\n",
            "fold4 Val Loss0.9003293178975582, Val ratio0.6522450733761405 Acc0.7144644382354433\n",
            "fold4 Test Loss0.884769681841135, Test ratio0.6515566141431847 Acc0.7140624933193749\n",
            "Train [0.45511831 0.74525545 0.82186472 0.84146313 0.84146313 0.76000792\n",
            " 0.84146313 0.69595952 0.84146313 0.86603326]\n",
            "Val [0.85527348 0.66299783 0.73477843 0.78759824 0.78759824 0.63119274\n",
            " 0.78759824 0.58489499 0.78759824 0.7067734 ]\n",
            "Test [0.86468712 0.66016192 0.73426273 0.78584359 0.78584359 0.63331933\n",
            " 0.78584359 0.58653934 0.78584359 0.71045577]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# d04-21"
      ],
      "metadata": {
        "id": "3tZOMgQifjwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## character gram + character间隔1的label"
      ],
      "metadata": {
        "id": "fAkUcLk8reml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gram_1 = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/gram_1_nopadding_include7_time3.npy')"
      ],
      "metadata": {
        "id": "TmxgKm_unPEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 0\n",
        "s_num = 3\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 1+4+7*2))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=200, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('Train', score[fold_idx-1, 0])\n",
        "    print('Validation', score[fold_idx-1, 1])\n",
        "    print('Test', score[fold_idx-1, 2])\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0421_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMpqqht6fmSA",
        "outputId": "dfe9f668-f7a3-4630-e56a-9115718ba2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4757\n",
            "EPOCH:0    Validation set: Average loss: 2.4748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:11,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.4725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:02<03:09,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8019\n",
            "EPOCH:50    Validation set: Average loss: 0.9891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:04<03:07,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.9758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:06<02:06,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4517\n",
            "EPOCH:100    Validation set: Average loss: 0.8520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:07<02:04,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:09<01:02,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3253\n",
            "EPOCH:150    Validation set: Average loss: 0.9050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:10<01:01,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:12<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.46724313 0.70257943 0.80306007 0.75966142 0.81245283 0.74001736\n",
            " 0.74001736 0.68848156 0.74001736 0.59195779 0.74001736 0.87572599\n",
            " 0.78972496 0.78972496 0.73035698 0.78972496 0.67328573 0.78972496\n",
            " 0.81472462]\n",
            "Validation [0.84856712 0.6330277  0.72503491 0.68227608 0.72296938 0.68326389\n",
            " 0.68326389 0.58794431 0.68326389 0.51493856 0.68326389 0.72742484\n",
            " 0.73027778 0.73027778 0.60088127 0.73027778 0.58293783 0.73027778\n",
            " 0.62866975]\n",
            "Test [0.82792147 0.63023296 0.71556217 0.67407072 0.71677847 0.68555556\n",
            " 0.68555556 0.58984783 0.68555556 0.51576096 0.68555556 0.73154507\n",
            " 0.73145833 0.73145833 0.60532321 0.73145833 0.58059599 0.73145833\n",
            " 0.64016982]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5150\n",
            "EPOCH:0    Validation set: Average loss: 2.5132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:15,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:03<03:10,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.6460\n",
            "EPOCH:50    Validation set: Average loss: 0.8613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:04<03:09,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.8320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:06<02:06,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3768\n",
            "EPOCH:100    Validation set: Average loss: 0.7965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:08<02:05,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.7695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:10<01:03,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2710\n",
            "EPOCH:150    Validation set: Average loss: 0.8917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:11<01:02,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:13<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.42528775 0.69759012 0.8448825  0.7559452  0.84022295 0.73942343\n",
            " 0.73942343 0.68064215 0.73942343 0.58047516 0.73942343 0.87266817\n",
            " 0.78744061 0.78744061 0.72072929 0.78744061 0.65132394 0.78744061\n",
            " 0.82776153]\n",
            "Validation [0.78339947 0.63445081 0.77059824 0.68764932 0.77026988 0.68784722\n",
            " 0.68784722 0.57980947 0.68784722 0.50082836 0.68784722 0.7327671\n",
            " 0.73006944 0.73006944 0.60210949 0.73006944 0.55839246 0.73006944\n",
            " 0.66712093]\n",
            "Test [0.7845412  0.63476425 0.77209631 0.69230667 0.769423   0.68854167\n",
            " 0.68854167 0.58415187 0.68854167 0.50399295 0.68854167 0.73660329\n",
            " 0.73534722 0.73534722 0.61191698 0.73534722 0.56853938 0.73534722\n",
            " 0.67430843]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5200\n",
            "EPOCH:0    Validation set: Average loss: 2.5300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:33,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:05<03:16,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8337\n",
            "EPOCH:50    Validation set: Average loss: 1.0285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:06<03:15,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.0197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:11<02:10,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4539\n",
            "EPOCH:100    Validation set: Average loss: 0.8754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:12<02:09,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:16<01:05,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3223\n",
            "EPOCH:150    Validation set: Average loss: 0.9288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:18<01:04,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.9328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:22<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.45385016 0.69221216 0.82777309 0.75809677 0.83079387 0.73476891\n",
            " 0.73476891 0.6766288  0.73476891 0.57861527 0.73476891 0.87016213\n",
            " 0.78014249 0.78014249 0.71240012 0.78014249 0.64504007 0.78014249\n",
            " 0.81047968]\n",
            "Validation [0.87542884 0.61086514 0.72879791 0.67217727 0.73130985 0.67185762\n",
            " 0.67185762 0.56038458 0.67185762 0.48739465 0.67185762 0.70402655\n",
            " 0.71760289 0.71760289 0.57710292 0.71760289 0.54233549 0.71760289\n",
            " 0.62263852]\n",
            "Test [0.8770977  0.6161667  0.73639921 0.674247   0.73532093 0.67069444\n",
            " 0.67069444 0.56107099 0.67069444 0.4879205  0.67069444 0.70854426\n",
            " 0.71236111 0.71236111 0.56989081 0.71236111 0.53432529 0.71236111\n",
            " 0.61633936]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5329\n",
            "EPOCH:0    Validation set: Average loss: 2.5364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:26,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:05<03:15,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7848\n",
            "EPOCH:50    Validation set: Average loss: 0.9330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:06<03:14,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.9538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:10<02:10,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4744\n",
            "EPOCH:100    Validation set: Average loss: 0.8271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:11<02:09,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.7954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:15<01:05,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3549\n",
            "EPOCH:150    Validation set: Average loss: 0.8689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:17<01:04,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:20<00:00,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.41800578 0.70126033 0.85669743 0.75523306 0.84653305 0.7474215\n",
            " 0.7474215  0.68392808 0.7474215  0.58657689 0.7474215  0.8753245\n",
            " 0.7855513  0.7855513  0.71579466 0.7855513  0.64411762 0.7855513\n",
            " 0.82582069]\n",
            "Validation [0.81455456 0.63247757 0.77161614 0.6788851  0.75645964 0.69480791\n",
            " 0.69480791 0.58199329 0.69480791 0.50461229 0.69480791 0.73227534\n",
            " 0.72473552 0.72473552 0.5898177  0.72473552 0.54807839 0.72473552\n",
            " 0.64669319]\n",
            "Test [0.79881863 0.63656389 0.77534135 0.68397967 0.76435416 0.6958426\n",
            " 0.6958426  0.58148573 0.6958426  0.50471588 0.6958426  0.72877001\n",
            " 0.7253198  0.7253198  0.59107313 0.7253198  0.547052   0.7253198\n",
            " 0.65258229]\n",
            "Train [0.4410967  0.69841051 0.83310327 0.75723411 0.83250068 0.7404078\n",
            " 0.7404078  0.68242015 0.7404078  0.58440628 0.7404078  0.8734702\n",
            " 0.78571484 0.78571484 0.71982027 0.78571484 0.65344184 0.78571484\n",
            " 0.81969663]\n",
            "Val [0.8304875  0.6277053  0.7490118  0.68024694 0.74525219 0.68444416\n",
            " 0.68444416 0.57753291 0.68444416 0.50194347 0.68444416 0.72412346\n",
            " 0.72567141 0.72567141 0.59247785 0.72567141 0.55793604 0.72567141\n",
            " 0.6412806 ]\n",
            "Test [0.82209475 0.62943195 0.74984976 0.68115101 0.74646914 0.68515857\n",
            " 0.68515857 0.5791391  0.68515857 0.50309757 0.68515857 0.72636566\n",
            " 0.72612162 0.72612162 0.59455103 0.72612162 0.55762816 0.72612162\n",
            " 0.64584997]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word gram"
      ],
      "metadata": {
        "id": "ewpVJDOszJkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/gram_word.npz')\n",
        "gram_1 = t['gram_1_word']\n",
        "gram_2 = t['gram_2_word']\n",
        "gram_3 = t['gram_3_word']\n",
        "del t"
      ],
      "metadata": {
        "id": "IkC1D7U1zRCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 1\n",
        "s_num = 2\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 9))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=200, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('Train', score[fold_idx-1, 0])\n",
        "    print('Validation', score[fold_idx-1, 1])\n",
        "    print('Test', score[fold_idx-1, 2])\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0421_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipbKVU14zHlu",
        "outputId": "d6a486f9-ddff-4db0-a83a-f2dfbe8b9776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5258\n",
            "EPOCH:0    Validation set: Average loss: 2.5229\n",
            "EPOCH:0    Test set: Average loss: 2.5263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:59<03:02,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8329\n",
            "EPOCH:50    Validation set: Average loss: 1.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:01<03:02,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 1.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:01<02:01,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4689\n",
            "EPOCH:100    Validation set: Average loss: 0.8910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:02<01:59,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:01<00:59,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3279\n",
            "EPOCH:150    Validation set: Average loss: 0.9287\n",
            "EPOCH:150    Test set: Average loss: 0.9084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:01<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.46058549 0.74196442 0.7883922  0.76231068 0.75882623 0.81833572\n",
            " 0.83616735 0.82506174 0.82890886]\n",
            "Validation [0.87678082 0.64681395 0.67601101 0.65931994 0.65221265 0.71884975\n",
            " 0.72353764 0.72106908 0.7226554 ]\n",
            "Test [0.86536886 0.64924272 0.68733727 0.67150208 0.65776168 0.72440065\n",
            " 0.73392474 0.734677   0.72608576]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5124\n",
            "EPOCH:0    Validation set: Average loss: 2.5229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:30,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.5017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:00<03:00,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7653\n",
            "EPOCH:50    Validation set: Average loss: 0.9822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:01<02:58,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.9512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:00<02:01,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3740\n",
            "EPOCH:100    Validation set: Average loss: 0.8348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:02<02:00,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.7775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:00<00:59,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2392\n",
            "EPOCH:150    Validation set: Average loss: 0.8477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:02<00:59,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:00<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.35912905 0.80035559 0.82219769 0.82091525 0.83381816 0.8484646\n",
            " 0.85614582 0.85732275 0.87586527]\n",
            "Validation [0.81781797 0.68703655 0.7051753  0.70935493 0.70644771 0.74005973\n",
            " 0.74287888 0.74851102 0.75689025]\n",
            "Test [0.7771355  0.70123092 0.71822032 0.72342636 0.72054391 0.75229564\n",
            " 0.75095536 0.76554557 0.76800847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5331\n",
            "EPOCH:0    Validation set: Average loss: 2.5273\n",
            "EPOCH:0    Test set: Average loss: 2.5318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:00<03:02,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7335\n",
            "EPOCH:50    Validation set: Average loss: 0.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:01<03:01,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.9248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:00<02:01,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4028\n",
            "EPOCH:100    Validation set: Average loss: 0.7883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:01<02:01,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:00<01:00,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2745\n",
            "EPOCH:150    Validation set: Average loss: 0.8043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:01<00:59,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.8937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:00<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.34368141 0.79794484 0.83675259 0.81702483 0.82170955 0.86756988\n",
            " 0.87717946 0.87180181 0.88352037]\n",
            "Validation [0.75797141 0.68479412 0.71991146 0.7050158  0.69635707 0.75569673\n",
            " 0.76568114 0.76415785 0.7624029 ]\n",
            "Test [0.86031855 0.69088161 0.72179661 0.71239734 0.70662619 0.76235707\n",
            " 0.77081771 0.77116569 0.77434765]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4265\n",
            "EPOCH:0    Validation set: Average loss: 2.4594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:01<04:14,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Test set: Average loss: 2.4381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [01:02<03:05,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.5870\n",
            "EPOCH:50    Validation set: Average loss: 0.9123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 51/200 [01:03<03:03,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Test set: Average loss: 0.8657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [02:04<02:04,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3131\n",
            "EPOCH:100    Validation set: Average loss: 0.8950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [02:05<02:05,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Test set: Average loss: 0.8687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [03:05<01:01,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2017\n",
            "EPOCH:150    Validation set: Average loss: 1.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 151/200 [03:06<01:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Test set: Average loss: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [04:06<00:00,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.41534869 0.74415607 0.79276789 0.76880529 0.76518644 0.83984307\n",
            " 0.85285284 0.84752802 0.85272329]\n",
            "Validation [0.83155328 0.66832027 0.70349705 0.68435468 0.67922616 0.75664055\n",
            " 0.75919743 0.75847897 0.76337295]\n",
            "Test [0.82266323 0.65854519 0.70037885 0.67975462 0.66922224 0.75093723\n",
            " 0.75856004 0.75866852 0.75877011]\n",
            "Train [0.39468616 0.77110523 0.81002759 0.79226401 0.79488509 0.84355332\n",
            " 0.85558637 0.85042858 0.86025445]\n",
            "Val [0.82103087 0.67174122 0.7011487  0.68951134 0.6835609  0.74281169\n",
            " 0.74782377 0.74805423 0.75133037]\n",
            "Test [0.83137153 0.67497511 0.70693326 0.6967701  0.68853851 0.74749765\n",
            " 0.75356446 0.75751419 0.756803  ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 重新写了一下 test函数\n",
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 3\n",
        "s_num = 2\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 9))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=200, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('Train', score[fold_idx-1, 0])\n",
        "    print('Validation', score[fold_idx-1, 1])\n",
        "    print('Test', score[fold_idx-1, 2])\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0421_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p06bxZIrrAYT",
        "outputId": "a025368a-635e-48ac-c2ef-07cc9f311e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4975\n",
            "EPOCH:0    Validation set: Average loss: 2.4953\n",
            "EPOCH:0    Test set: Average loss: 2.4974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:55<02:32,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7997\n",
            "EPOCH:50    Validation set: Average loss: 0.9961\n",
            "EPOCH:50    Test set: Average loss: 1.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:45<01:41,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4344\n",
            "EPOCH:100    Validation set: Average loss: 0.9182\n",
            "EPOCH:100    Test set: Average loss: 0.9181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:36<00:50,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2912\n",
            "EPOCH:150    Validation set: Average loss: 0.9603\n",
            "EPOCH:150    Test set: Average loss: 0.9734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:26<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.42605329 0.76445784 0.80457381 0.78050756 0.78692196 0.81716165\n",
            " 0.83753582 0.82078082 0.83450275]\n",
            "Validation [0.90318582 0.65161299 0.68731743 0.66351369 0.66585181 0.69839093\n",
            " 0.72147087 0.70434369 0.71198108]\n",
            "Test [0.90757389 0.6529567  0.68165721 0.66345072 0.663733   0.7004017\n",
            " 0.71327344 0.70257987 0.7072663 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4974\n",
            "EPOCH:0    Validation set: Average loss: 2.4998\n",
            "EPOCH:0    Test set: Average loss: 2.4953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:52<02:34,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7518\n",
            "EPOCH:50    Validation set: Average loss: 0.9243\n",
            "EPOCH:50    Test set: Average loss: 0.9167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:44<01:43,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4131\n",
            "EPOCH:100    Validation set: Average loss: 0.8607\n",
            "EPOCH:100    Test set: Average loss: 0.8176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:35<00:51,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2885\n",
            "EPOCH:150    Validation set: Average loss: 0.9521\n",
            "EPOCH:150    Test set: Average loss: 0.8791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:25<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.41135543 0.76423152 0.80780175 0.79448711 0.78243609 0.84697046\n",
            " 0.86099765 0.85888112 0.85837004]\n",
            "Validation [0.85125483 0.68248162 0.70749709 0.70656085 0.69240142 0.76053071\n",
            " 0.7600128  0.7702577  0.76657182]\n",
            "Test [0.80471074 0.69025928 0.7271476  0.71991152 0.70105412 0.76579773\n",
            " 0.77885759 0.78181812 0.77177678]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5451\n",
            "EPOCH:0    Validation set: Average loss: 2.5445\n",
            "EPOCH:0    Test set: Average loss: 2.5436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:51<02:35,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7129\n",
            "EPOCH:50    Validation set: Average loss: 0.8931\n",
            "EPOCH:50    Test set: Average loss: 0.9082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:42<01:41,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.3794\n",
            "EPOCH:100    Validation set: Average loss: 0.7881\n",
            "EPOCH:100    Test set: Average loss: 0.8035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:33<00:50,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2637\n",
            "EPOCH:150    Validation set: Average loss: 0.8782\n",
            "EPOCH:150    Test set: Average loss: 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:24<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.36180248 0.79490169 0.83103239 0.81512877 0.81610394 0.86366477\n",
            " 0.87571938 0.87174977 0.8786257 ]\n",
            "Validation [0.7601653  0.7032844  0.73217679 0.7193938  0.71584208 0.77383098\n",
            " 0.78095521 0.77911669 0.7812975 ]\n",
            "Test [0.80179576 0.70143366 0.73135536 0.71693183 0.71299158 0.77279169\n",
            " 0.78160949 0.77957653 0.78150862]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.5102\n",
            "EPOCH:0    Validation set: Average loss: 2.5094\n",
            "EPOCH:0    Test set: Average loss: 2.5136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:51<02:36,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.7663\n",
            "EPOCH:50    Validation set: Average loss: 0.9297\n",
            "EPOCH:50    Test set: Average loss: 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:43<01:42,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4188\n",
            "EPOCH:100    Validation set: Average loss: 0.8532\n",
            "EPOCH:100    Test set: Average loss: 0.9378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:34<00:50,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2855\n",
            "EPOCH:150    Validation set: Average loss: 0.9131\n",
            "EPOCH:150    Test set: Average loss: 0.9638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:25<00:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.45691931 0.7566462  0.78652482 0.77583803 0.77937084 0.83485406\n",
            " 0.83827779 0.84062001 0.85148113]\n",
            "Validation [0.83535976 0.65529037 0.68626437 0.67651229 0.668752   0.73586753\n",
            " 0.74305652 0.742642   0.74518833]\n",
            "Test [0.90853204 0.65618034 0.68464696 0.67664609 0.66869172 0.7354599\n",
            " 0.73583077 0.73746889 0.744329  ]\n",
            "Train [0.41403263 0.77005931 0.80748319 0.79149037 0.79120821 0.84066273\n",
            " 0.85313266 0.84800793 0.85574491]\n",
            "Val [0.83749143 0.67316735 0.70331392 0.69149516 0.68571183 0.74215504\n",
            " 0.75137385 0.74909002 0.75125968]\n",
            "Test [0.85565311 0.6752075  0.70620178 0.69423504 0.68661761 0.74361276\n",
            " 0.75239282 0.75036085 0.75122018]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word gram + 12 -100 label"
      ],
      "metadata": {
        "id": "VNwFgJu5b1-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.load('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Code Continuous Data/gram_word.npz')\n",
        "gram_1 = t['gram_1_word']\n",
        "gram_2 = t['gram_2_word']\n",
        "gram_3 = t['gram_3_word']\n",
        "del t"
      ],
      "metadata": {
        "id": "4PdcuJxRb6yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "ID_list = [1,2,3,4,5,6]\n",
        "model_name_list = ['mlp', 'SVC']\n",
        "\n",
        "save_number = 2\n",
        "s_num = 4\n",
        "\n",
        "for m_idx in range(1):\n",
        "  model_list = []\n",
        "  for ID in range(1, 7):\n",
        "    model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "    model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "    model_list.append(model_stroke)\n",
        "\n",
        "  score = np.zeros((4, 3, 9))\n",
        "  for fold_idx in range(1, 5):\n",
        "    test_dataset = MyDataset(ID_list, R_time_list=[fold_idx], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    test_loader = Data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    x = fold_idx+1 if fold_idx+1<=5 else 1\n",
        "    val_dataset = MyDataset(ID_list, R_time_list=[x], model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    val_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    R_time_list = []\n",
        "    for i in range(1, 9):\n",
        "      if i!=fold_idx and i!=x:\n",
        "        R_time_list.append(i)\n",
        "    train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=s_num)\n",
        "    train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "      \n",
        "    model_param=64\n",
        "    score[fold_idx-1] = main_function(total_epoch=200, dataloader_list=[train_loader, val_loader, test_loader], \\\n",
        "                                  model_para=model_param, model_save=False, cross_val=True, weight_decay=1e-4)\n",
        "    print('Train', score[fold_idx-1, 0])\n",
        "    print('Validation', score[fold_idx-1, 1])\n",
        "    print('Test', score[fold_idx-1, 2])\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  np.save(result_path + '/STROKE_d0421_score_' + str(save_number), score)\n",
        "  save_number += 1\n",
        "\n",
        "  x = np.mean(score, axis=0)\n",
        "  print('Train', x[0])\n",
        "  print('Val', x[1])\n",
        "  print('Test', x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnV-zqLJb8hM",
        "outputId": "6975e5af-3834-4718-bcfd-f839abd61877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4728\n",
            "EPOCH:0    Validation set: Average loss: 2.4621\n",
            "EPOCH:0    Test set: Average loss: 2.4628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:47<02:23,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8370\n",
            "EPOCH:50    Validation set: Average loss: 1.0494\n",
            "EPOCH:50    Test set: Average loss: 1.0578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:35<01:35,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4799\n",
            "EPOCH:100    Validation set: Average loss: 0.9155\n",
            "EPOCH:100    Test set: Average loss: 0.9476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:23<00:48,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3368\n",
            "EPOCH:150    Validation set: Average loss: 0.9463\n",
            "EPOCH:150    Test set: Average loss: 0.9967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:11<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.46650361 0.80802711 0.83467932 0.82448238 0.82654128 0.83176115\n",
            " 0.84800922 0.84280948 0.84567599]\n",
            "Validation [0.89776442 0.69154132 0.71210914 0.70852697 0.69858851 0.72324942\n",
            " 0.73445361 0.73645905 0.72939796]\n",
            "Test [0.93190025 0.6854782  0.70328648 0.7011675  0.6965781  0.71871907\n",
            " 0.72429401 0.72963758 0.72518881]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4896\n",
            "EPOCH:0    Validation set: Average loss: 2.4883\n",
            "EPOCH:0    Test set: Average loss: 2.4889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:48<02:25,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.8180\n",
            "EPOCH:50    Validation set: Average loss: 1.0300\n",
            "EPOCH:50    Test set: Average loss: 0.9905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:37<01:37,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4274\n",
            "EPOCH:100    Validation set: Average loss: 0.9176\n",
            "EPOCH:100    Test set: Average loss: 0.8612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:26<00:48,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.2785\n",
            "EPOCH:150    Validation set: Average loss: 0.9698\n",
            "EPOCH:150    Test set: Average loss: 0.9329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:14<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.4515212  0.79895558 0.82313785 0.82464904 0.82478037 0.83148931\n",
            " 0.84167145 0.84968916 0.85261407]\n",
            "Validation [0.90842391 0.68203724 0.70524672 0.70399987 0.69958893 0.72065079\n",
            " 0.72769867 0.73582236 0.73335842]\n",
            "Test [0.87120296 0.68781735 0.71003814 0.70636786 0.70204013 0.72377896\n",
            " 0.72910641 0.73880331 0.73497953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4998\n",
            "EPOCH:0    Validation set: Average loss: 2.5142\n",
            "EPOCH:0    Test set: Average loss: 2.4958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:48<02:22,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.9261\n",
            "EPOCH:50    Validation set: Average loss: 1.0872\n",
            "EPOCH:50    Test set: Average loss: 1.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:36<01:35,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.5352\n",
            "EPOCH:100    Validation set: Average loss: 0.8709\n",
            "EPOCH:100    Test set: Average loss: 0.9275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:23<00:47,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3783\n",
            "EPOCH:150    Validation set: Average loss: 0.8830\n",
            "EPOCH:150    Test set: Average loss: 0.9367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:11<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.45206472 0.84220194 0.8613435  0.86231499 0.87183167 0.86013182\n",
            " 0.87081916 0.87399892 0.88246725]\n",
            "Validation [0.8635174  0.71494586 0.73070088 0.73022676 0.73427039 0.7451553\n",
            " 0.74994655 0.75387984 0.75952847]\n",
            "Test [0.91873207 0.71529113 0.72919578 0.73339627 0.73391478 0.74348967\n",
            " 0.74763791 0.75122746 0.757062  ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0    Train set: Average loss: 2.4985\n",
            "EPOCH:0    Validation set: Average loss: 2.4980\n",
            "EPOCH:0    Test set: Average loss: 2.5033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 50/200 [00:47<02:23,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:50    Train set: Average loss: 0.9258\n",
            "EPOCH:50    Validation set: Average loss: 1.1674\n",
            "EPOCH:50    Test set: Average loss: 1.1544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [01:35<01:36,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:100    Train set: Average loss: 0.4901\n",
            "EPOCH:100    Validation set: Average loss: 1.0729\n",
            "EPOCH:100    Test set: Average loss: 1.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 150/200 [02:23<00:48,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:150    Train set: Average loss: 0.3358\n",
            "EPOCH:150    Validation set: Average loss: 1.1232\n",
            "EPOCH:150    Test set: Average loss: 1.0702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [03:12<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train [0.52470355 0.79198981 0.81164934 0.80872718 0.81874587 0.81150155\n",
            " 0.82370798 0.82614435 0.83485297]\n",
            "Validation [1.03905231 0.64681367 0.67168082 0.66251163 0.65945112 0.66485798\n",
            " 0.68457141 0.68189442 0.67521524]\n",
            "Test [1.02168284 0.65026955 0.67025619 0.66451907 0.66346068 0.66970769\n",
            " 0.68446425 0.68230842 0.67881095]\n",
            "Train [0.47369827 0.81029361 0.8327025  0.8300434  0.8354748  0.83372096\n",
            " 0.84605195 0.84816048 0.85390257]\n",
            "Val [0.92718951 0.68383452 0.70493439 0.70131631 0.69797474 0.71347837\n",
            " 0.72416756 0.72701392 0.72437502]\n",
            "Test [0.93587953 0.68471406 0.70319415 0.70136267 0.69899842 0.71392385\n",
            " 0.72137564 0.72549419 0.72401032]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(Stroke_i==Class_j) = P(Class_{(i,j)}) * P(Class_j|Stroke_{i-1},..., Stroke_{i-N})$, where $N=1,2,3$"
      ],
      "metadata": {
        "id": "mgrnjDhfXJB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(Stroke_i==Class_j) = P(Class_{(i,j)}) * P(Class_j|Stroke_{i-1},..., Stroke_{i-N})$"
      ],
      "metadata": {
        "id": "YpfnOBTPXcXv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWdJZxogXZ6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and predict on sentence"
      ],
      "metadata": {
        "id": "2e1XONqRzhoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "1OtHgCU_2M-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ID_list = [1,2,3,4,5,6]\n",
        "R_time_list = [1,2,3,4,5,6,7,8]\n",
        "model_list = []\n",
        "m_idx = 0\n",
        "for ID in range(1, 7):\n",
        "  model_name = result_path_isolated + '/'+ model_name_list[m_idx] + '_sub00' + str(ID) + '.pck'\n",
        "  model_stroke = pickle.load(open(model_name, \"rb\"))\n",
        "  model_list.append(model_stroke)\n",
        "train_dataset = MyDataset(ID_list, R_time_list=R_time_list, model_list=model_list, flatten=True, model_type=0, s_num=2)\n",
        "train_loader = Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "NvrmPQLpzqU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "model = My_CNN_5_lstm_stroke().to(device)\n",
        "\n",
        "weight_decay=1e-4\n",
        "total_epoch = 120\n",
        "\n",
        "optmizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=weight_decay)  \n",
        "scheduler = lr_scheduler.StepLR(optmizer, step_size=50, gamma=0.5, verbose=False) \n",
        "weight=torch.tensor(weights).to(device).float()\n",
        "criterion = nn.CrossEntropyLoss(weight=weight).to(device)  \n",
        "    \n",
        "    \n",
        "for i in tqdm(range(total_epoch)):\n",
        "  _, model = Train_model(model, i, optmizer, criterion, train_loader)\n",
        "  scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS11UYSUz5uB",
        "outputId": "470ab2b1-34f7-47b2-eb89-e84c1b82550d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "100%|██████████| 120/120 [00:32<00:00,  3.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "# sentence\n",
        "# path /content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous/001/test/EOG_001_01_001.csv\n",
        "sentence_seg = torch.zeros((0, 1024, 2))\n",
        "prob_seg = torch.zeros((0, 16, 36))\n",
        "root_dir = '/content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous/00'\n",
        "\n",
        "for ID in tqdm(range(1, 7)):\n",
        "  model_name = result_path_isolated + '/mlp_sub00' + str(ID) + '.pck'\n",
        "  model_sub = pickle.load(open(model_name, \"rb\"))\n",
        "  for i in range(1, 26):\n",
        "    sent_str = '0' + str(i) if i<10 else str(i)\n",
        "    sentence_ = pd.read_csv(root_dir  + str(ID) + '/test/EOG_00' + str(ID) + '_01_0' + sent_str + '.csv').to_numpy()\n",
        "    n_ = int(np.floor(sentence_.shape[0]/6))\n",
        "    for j in range(6):\n",
        "      seg_r = signal.resample(sentence_[(j*n_):((j+1)*n_)], 1024, axis=0)\n",
        "      seg_r = torch.tensor(seg_r)\n",
        "      sentence_seg = torch.cat((sentence_seg, seg_r.reshape((1, 1024, 2))), dim=0)\n",
        "\n",
        "      s = stroke_probability_map_1(seg_r, model_sub, flatten=True, model_type=0)\n",
        "      s = torch.from_numpy(s).reshape((1, 16, 36))\n",
        "\n",
        "      prob_seg = torch.cat((prob_seg, s), dim=0)\n",
        "\n",
        "\n",
        "sentence_seg = sentence_seg.float().to(device)\n",
        "prob_seg = prob_seg.float().to(device)\n",
        "print(sentence_seg.shape, prob_seg.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSAqx7zA0dM9",
        "outputId": "eb9846f4-4d5a-4888-c8c8-af40244fbadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:35<00:00,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([900, 1024, 2]) torch.Size([900, 16, 36])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "DAHjXqHj2P4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous/50character_label.xlsx', header=None)\n",
        "f2 = open(\"/content/drive/MyDrive/Colab Notebooks/MLMA/project/Data/continuous/test_sent.jp.txt\",\"r\")\n",
        "lines = f2.readlines()\n",
        "\n",
        "w = lines[0][7:-1].split(' ')\n",
        "print(w[2][1], y.iloc[60, 0])\n",
        "print(w[2][1] ==  y.iloc[60, 0])\n",
        "y.loc[70] = [w[2][1], ' ', y.iloc[60, 2]]\n",
        "\n",
        "\n",
        "w = lines[3][7:-1].split(' ')\n",
        "print(w[5][3], y.iloc[59, 0])\n",
        "print(w[5][3] ==  y.iloc[59, 0])\n",
        "y.loc[71] = [w[5][3], ' ', y.iloc[59, 2]]\n",
        "\n",
        "w = lines[1][7:-1].split(' ')\n",
        "print(w[4][2], y.iloc[28, 0])\n",
        "print(w[4][2] ==  y.iloc[28, 0])\n",
        "y.loc[72] = [w[4][2], ' ', y.iloc[28, 2]]\n",
        "\n",
        "\n",
        "charc_list = []\n",
        "for i in range(y.shape[0]):\n",
        "    cur_ = []\n",
        "    temp = y.iloc[i, 2][1:-1].split(',')\n",
        "    for k in range(len(temp)):\n",
        "        cur_.append(int(temp[k]))\n",
        "    charc_list.append(cur_)\n",
        "            \n",
        "\n",
        "sent_label = []\n",
        "for idx in range(len(lines)):\n",
        "    line3 = lines[idx]\n",
        "    sent_label.append([])\n",
        "    w = line3[7:-1].split(' ')\n",
        "    for i in range(len(w)):\n",
        "        for j in range(len(w[i])):\n",
        "            # check through y\n",
        "            find = False\n",
        "            for k in range(y.shape[0]):\n",
        "                if w[i][j] == y.iloc[k, 0]:\n",
        "                    find = True\n",
        "                    for m in range(len(charc_list[k])):\n",
        "                        sent_label[-1].append(charc_list[k][m])\n",
        "            if find == False:\n",
        "                print(w[i][j], idx, i, j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E93EMPJ_-4u",
        "outputId": "2aa6d2a6-9144-412c-80d0-05503f0c9b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ョ ヨ\n",
            "False\n",
            "ュ ユ\n",
            "False\n",
            "ッ ツ\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(sentence_seg, prob_seg)\n",
        "output_label = output.cpu().argmax(dim=1).numpy()\n",
        "output = output.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "result_0 = []\n",
        "result_1 = []\n",
        "result_2 = []\n",
        "result_3 = []\n",
        "for i in range(output.shape[0]):\n",
        "  idx = np.where(output_label[i] != 12)[0]\n",
        "  result_0.append(list(output_label[i][idx]))\n",
        "\n",
        "  # 1\n",
        "  r_ = [output[i, :-1, 0].argmax()]\n",
        "  for j in range(1, 16):\n",
        "    prob_ = np.multiply(output[i, :, j], gram_1[r_[-1]])\n",
        "    p_next = int(prob_.argmax())\n",
        "    if p_next == 12:\n",
        "      break\n",
        "    else:\n",
        "      r_.append(p_next)\n",
        "  result_1.append(r_)\n",
        "\n",
        "  # 2\n",
        "  r_ = [output[i, :-1, 0].argmax(), output[i, :-1, 1].argmax()]\n",
        "  for j in range(2, 16):\n",
        "    prob_ = np.multiply(output[i, :, j], gram_2[r_[-2], r_[-1]])\n",
        "    p_next = int(prob_.argmax())\n",
        "    if p_next == 12:\n",
        "      break\n",
        "    else:\n",
        "      r_.append(p_next)\n",
        "  result_2.append(r_)\n",
        "\n",
        "  # 3\n",
        "  r_ = [output[i, :-1, 0].argmax(), output[i, :-1, 1].argmax(), output[i, :-1, 2].argmax()]\n",
        "  for j in range(2, 16):\n",
        "    prob_ = np.multiply(output[i, :, j], gram_3[r_[-3], r_[-2], r_[-1]])\n",
        "    p_next = int(prob_.argmax())\n",
        "    if p_next == 12:\n",
        "      break\n",
        "    else:\n",
        "      r_.append(p_next)\n",
        "  result_3.append(r_)\n",
        "\n"
      ],
      "metadata": {
        "id": "WlssWcye4Nij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_result = np.zeros((6, 4, 25))\n",
        "ratio_rle_result = np.zeros((6, 4, 25))\n",
        "\n",
        "for ID in range(1, 7):\n",
        "  for s_idx in range(1, 26):\n",
        "    b_idx = int((ID-1)*(6*25)+(s_idx-1) * 6)\n",
        "    for i in range(4):\n",
        "      if i == 0:\n",
        "        r_c = result_0\n",
        "      elif i == 1:\n",
        "        r_c = result_1\n",
        "      elif i == 2:\n",
        "        r_c = result_2\n",
        "      elif i == 3:\n",
        "        r_c = result_3\n",
        "      else:\n",
        "        print('i error')\n",
        "      result_c = []\n",
        "      for cut_idx in range(6):\n",
        "        result_c = result_c + r_c[b_idx+cut_idx]\n",
        "\n",
        "      ratio_result[ID-1, i, s_idx-1] = ratio(result_c, sent_label[s_idx-1])\n",
        "\n",
        "      result_c = rle(result_c)\n",
        "      s_rle = rle(sent_label[s_idx-1])\n",
        "      ratio_rle_result[ID-1, i, s_idx-1] = ratio(result_c, s_rle)"
      ],
      "metadata": {
        "id": "CS7ODIZuKSIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(np.mean(ratio_result, axis=-1), axis=0))\n",
        "print(np.mean(np.mean(ratio_rle_result, axis=-1), axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaQD4HWt8Hqc",
        "outputId": "4404e14a-714f-4dfa-d769-e1fac2d3288f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.53603532 0.54556513 0.53610813 0.50408278]\n",
            "[0.5576614  0.55441889 0.55507792 0.55136716]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('STROKE_d0421_score_ratio', ratio_result=ratio_result, ratio_rle_result=ratio_rle_result)"
      ],
      "metadata": {
        "id": "dNhrSL7k8okd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}