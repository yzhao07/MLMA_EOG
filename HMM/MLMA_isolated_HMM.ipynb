{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93JVKqQAQjb6",
        "outputId": "1ce8d2af-5835-4ad9-813a-ffaba3b0b486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.5/160.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "import librosa\n",
        "from hmmlearn import hmm\n",
        "from scipy.stats import kurtosis, skew\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score\n",
        "from preprocess import preprocess\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ANC_PGKHQlJx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get file list for 1 patient\n",
        "def get_file_list(path):\n",
        "  file_list = []\n",
        "  label = []\n",
        "  for i in os.listdir(path):\n",
        "    if i[0] == 'E':\n",
        "      file_list.append(i)\n",
        "      l = int(i.split(\"_\")[-1].split(\".\")[0])-1\n",
        "      label.append(l)\n",
        "  return label,file_list"
      ],
      "metadata": {
        "id": "gh0gy5ZiQs04"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature from 1 file and preprocess\n",
        "def get_feature(path):\n",
        "    f = []\n",
        "    a = pd.read_csv(path,names=[\"vertical\",\"horizontal\"])\n",
        "    a = np.array(a)\n",
        "    #print(a.shape)\n",
        "    a = preprocess(a)\n",
        "    #print(a.shape)\n",
        "    for j in a[:,0]:\n",
        "        f.append(j)        \n",
        "    for j in a[:,1]:\n",
        "        f.append(j)\n",
        "    return f"
      ],
      "metadata": {
        "id": "yP7JwhaaTPYO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self identified test_split\n",
        "def my_train_test_split_user_dependent(path,test_split,val_split,file_list,label):\n",
        "  X_test = dict({})\n",
        "  X_train = dict({})\n",
        "  X_val = dict({})\n",
        "  for i in range(12):\n",
        "    X_test[i] = []\n",
        "    X_train[i] = []\n",
        "    X_val[i] = []\n",
        "  for f in range(len(file_list)):\n",
        "    file = file_list[f]\n",
        "    file_label = label[f]\n",
        "    feature = get_feature(str(path+file))\n",
        "    if file.split('_')[2] in test_split:\n",
        "      X_test[file_label].append(feature)\n",
        "    elif file.split('_')[2] == val_split:\n",
        "      X_val[file_label].append(feature)\n",
        "    else:\n",
        "      X_train[file_label].append(feature)\n",
        "  \n",
        "  return X_train,X_test,X_val"
      ],
      "metadata": {
        "id": "TAp_v61UTSHx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    f1_micro = f1_score(y_true, y_pred,average = 'micro')\n",
        "    f1_macro = f1_score(y_true, y_pred,average = 'macro')\n",
        "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
        "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
        "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc"
      ],
      "metadata": {
        "id": "IXLK5rkITWkL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Dependent"
      ],
      "metadata": {
        "id": "AWWct-RdTbLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "test_split = [[\"01\",\"02\"],[\"03\",\"04\"],[\"05\",\"06\"],[\"07\",\"08\"],[\"09\",\"10\"]]\n",
        "val_split = ['03','01',\"04\",\"05\",\"06\"]"
      ],
      "metadata": {
        "id": "2wBw5RDoTYyy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search(path, file_list, label):\n",
        "  n_components = [2,3]\n",
        "  grid_search_output = []\n",
        "  for ncp in n_components:\n",
        "    output = dict()\n",
        "    output[\"n_components\"] = ncp\n",
        "    \n",
        "    clf_list = []\n",
        "    val_pred = []\n",
        "    val_label = []\n",
        "    test_pred = []\n",
        "    test_label = []\n",
        "    for t in range(len(val_split)):\n",
        "      X_train,X_test,X_val= my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)\n",
        "      for k in range(12):\n",
        "        X_train_stroke = np.array(X_train[k])\n",
        "        clf = hmm.GaussianHMM(n_components=ncp,random_state=42)\n",
        "        clf.fit(X_train_stroke)\n",
        "        clf_list.append(clf)\n",
        "      pred = np.zeros((3,12))\n",
        "      for i in range(12):\n",
        "        score = np.zeros((3,12))\n",
        "        for j in range(12):\n",
        "          X_val_stroke = np.array(X_val[i])\n",
        "          X_test_stroke = np.array(X_test[i])\n",
        "          clf = clf_list[j]\n",
        "          score[0,j] = clf.score(X_val_stroke)\n",
        "          score[1,j] = clf.score(X_test_stroke[0].reshape(1, -1))\n",
        "          score[2,j] = clf.score(X_test_stroke[1].reshape(1, -1))\n",
        "        pred[:,i] = np.argmax(score,axis=1)\n",
        "      val_pred.extend(list(pred[0,:]))\n",
        "      val_label.extend(list(np.arange(12)))\n",
        "      test_pred.extend(list(pred[1,:]))\n",
        "      test_pred.extend(list(pred[2,:]))\n",
        "      test_label.extend(list(np.arange(12)))\n",
        "      test_label.extend(list(np.arange(12)))\n",
        "    #test_label = np.array(test_label)\n",
        "    #test_pred = np.array(test_pred)\n",
        "    val_f1_micro,val_f1_macro,val_precision_micro,val_precision_macro,val_recall_micro,val_recall_macro,val_acc = evaluate(val_label,val_pred)\n",
        "    test_f1_micro,test_f1_macro,test_precision_micro,test_precision_macro,test_recall_micro,test_recall_macro,test_acc = evaluate(test_label,test_pred)\n",
        "    output[\"val_Accuracy\"] = val_acc\n",
        "    output[\"val_f1_micro\"] = val_f1_micro\n",
        "    output[\"val_f1_macro\"] = val_f1_macro\n",
        "    output[\"val_precision_micro\"]= val_precision_micro\n",
        "    output[\"val_precision_macro\"]= val_precision_macro\n",
        "    output[\"val_recall_micro\"]= val_recall_micro\n",
        "    output[\"val_recall_macro\"]= val_recall_macro\n",
        "    \n",
        "    output[\"test_Accuracy\"] = test_acc\n",
        "    output[\"test_f1_micro\"] = test_f1_micro\n",
        "    output[\"test_f1_macro\"] = test_f1_macro\n",
        "    output[\"test_precision_micro\"]= test_precision_micro\n",
        "    output[\"test_precision_macro\"]= test_precision_macro\n",
        "    output[\"test_recall_micro\"]= test_recall_micro\n",
        "    output[\"test_recall_macro\"]= test_recall_macro\n",
        "    grid_search_output.append(output)\n",
        "  return grid_search_output"
      ],
      "metadata": {
        "id": "BIr-zC4uWyPL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in patient:\n",
        "    print(p)\n",
        "    path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+p+\"/isolated_strokes/\")\n",
        "    for t in range(len(test_split)):\n",
        "        print(test_split[t])\n",
        "        label,file_list = get_file_list(path)\n",
        "        X_train,X_test,X_val = my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)"
      ],
      "metadata": {
        "id": "E7s7NXfCUBWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec76073d-8d66-4105-ee38-b760679f672e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n",
            "002\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n",
            "003\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n",
            "004\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n",
            "005\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n",
            "006\n",
            "['01', '02']\n",
            "['03', '04']\n",
            "['05', '06']\n",
            "['07', '08']\n",
            "['09', '10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = \"006\"\n",
        "path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+p+\"/isolated_strokes/\")\n",
        "label,file_list = get_file_list(path)\n",
        "val_pred = []\n",
        "val_label = []\n",
        "test_pred = []\n",
        "test_label = []\n",
        "for t in range(len(val_split)):\n",
        "  X_train,X_test,X_val= my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)\n",
        "  clf_list = []\n",
        "  for k in range(12):\n",
        "    X_train_stroke = np.array(X_train[k])\n",
        "    clf = hmm.GaussianHMM(n_components=2, random_state=42)\n",
        "    clf.fit(X_train_stroke)\n",
        "    clf_list.append(clf)\n",
        "  pred = np.zeros((3,12))\n",
        "  for i in range(12):\n",
        "    score = np.zeros((3,12))\n",
        "    for j in range(12):\n",
        "      X_val_stroke = np.array(X_val[i])\n",
        "      X_test_stroke = np.array(X_test[i])\n",
        "      clf = clf_list[j]\n",
        "      score[0,j] = clf.score(X_val_stroke)\n",
        "      score[1,j] = clf.score(X_test_stroke[0].reshape(1, -1))\n",
        "      score[2,j] = clf.score(X_test_stroke[1].reshape(1, -1))\n",
        "    pred[:,i] = np.argmax(score,axis=1)\n",
        "  val_pred.extend(list(pred[0,:]))\n",
        "  val_label.extend(list(np.arange(12)))\n",
        "  test_pred.extend(list(pred[1,:]))\n",
        "  test_pred.extend(list(pred[2,:]))\n",
        "  test_label.extend(list(np.arange(12)))\n",
        "  test_label.extend(list(np.arange(12)))\n",
        "val_f1_micro,val_f1_macro,val_precision_micro,val_precision_macro,val_recall_micro,val_recall_macro,val_acc = evaluate(val_label,val_pred)\n",
        "test_f1_micro,test_f1_macro,test_precision_micro,test_precision_macro,test_recall_micro,test_recall_macro,test_acc = evaluate(test_label,test_pred)\n",
        "print(\"validation f1 micro:\", val_f1_micro)\n",
        "print(\"validation f1 macro:\", val_f1_macro)\n",
        "print(\"validation precision micro\", val_precision_micro)\n",
        "print(\"validation precision macro\", val_precision_macro)\n",
        "print(\"validation recall micro\", val_recall_micro)\n",
        "print(\"validation recall macro\", val_recall_macro)\n",
        "print(\"validation accuracy\", val_acc)\n",
        "print(\"test f1 micro:\", test_f1_micro)\n",
        "print(\"test f1 macro:\", test_f1_macro)\n",
        "print(\"test precision micro\", test_precision_micro)\n",
        "print(\"test precision macro\", test_precision_macro)\n",
        "print(\"test recall micro\", test_recall_micro)\n",
        "print(\"test recall macro\", test_recall_macro)\n",
        "print(\"test accuracy\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-6IeKFpVOOX",
        "outputId": "51771d9b-21c1-4fd6-b87f-3fca72697708"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.base:Model is not converging.  Current: 1994.501626001713 is not greater than 2044.0982391325783. Delta is -49.59661313086531\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2238.150945244983 is not greater than 2248.5836475118076. Delta is -10.432702266824435\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 1983.4089078832558 is not greater than 1997.4804647938386. Delta is -14.071556910582785\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2111.7622714644203 is not greater than 2153.1942843823253. Delta is -41.43201291790501\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 1845.3348897446442 is not greater than 1860.0528380286755. Delta is -14.717948284031309\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2000.4986759050723 is not greater than 2083.1302153672536. Delta is -82.63153946218131\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 1953.1945644477992 is not greater than 1954.225391343158. Delta is -1.030826895358814\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2041.9468620163368 is not greater than 2071.111053686971. Delta is -29.16419167063418\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2080.5354871632085 is not greater than 2107.1142718983174. Delta is -26.57878473510891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation f1 micro: 0.8666666666666667\n",
            "validation f1 macro: 0.8688552188552188\n",
            "validation precision micro 0.8666666666666667\n",
            "validation precision macro 0.8791666666666668\n",
            "validation recall micro 0.8666666666666667\n",
            "validation recall macro 0.8666666666666667\n",
            "validation accuracy 0.8666666666666667\n",
            "test f1 micro: 0.8583333333333333\n",
            "test f1 macro: 0.8642874342719544\n",
            "test precision micro 0.8583333333333333\n",
            "test precision macro 0.8802188552188553\n",
            "test recall micro 0.8583333333333333\n",
            "test recall macro 0.8583333333333333\n",
            "test accuracy 0.8583333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = \"002\"\n",
        "path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+p+\"/isolated_strokes/\")\n",
        "label,file_list = get_file_list(path)\n",
        "grid_search_output = grid_search(path, file_list, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVKsLaC2lTdJ",
        "outputId": "1c552db6-5811-4497-deca-dff2647c1c9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2169.3810440496322 is not greater than 2255.7611146518475. Delta is -86.38007060221526\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2396.1111846070276 is not greater than 2473.9914120889093. Delta is -77.88022748188178\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2182.275850089831 is not greater than 2203.5403642550045. Delta is -21.26451416517375\n",
            "WARNING:hmmlearn.base:Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2363.7371986738312 is not greater than 2408.5419285695325. Delta is -44.80472989570126\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2273.4100604870227 is not greater than 2438.7601882473523. Delta is -165.35012776032954\n",
            "WARNING:hmmlearn.base:Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2108.169465425786 is not greater than 2151.399376347806. Delta is -43.22991092202028\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2366.107766165916 is not greater than 2434.875708390746. Delta is -68.76794222482977\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2176.922098947167 is not greater than 2227.5555183257147. Delta is -50.63341937854784\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2226.292034812038 is not greater than 2378.6122348469603. Delta is -152.32020003492244\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2291.1594777414716 is not greater than 2508.133704632057. Delta is -216.97422689058521\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2353.801045770085 is not greater than 2374.247875950917. Delta is -20.44683018083242\n",
            "WARNING:hmmlearn.base:Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2109.733538519102 is not greater than 2150.84971703289. Delta is -41.11617851378833\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2265.2622861344753 is not greater than 2443.706138998182. Delta is -178.44385286370652\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2347.14257243366 is not greater than 2350.9032111742727. Delta is -3.7606387406126487\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2228.718160113718 is not greater than 2479.1851915658012. Delta is -250.46703145208312\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2070.7896747295113 is not greater than 2070.7896953969785. Delta is -2.0667467197199585e-05\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2139.7850735420934 is not greater than 2183.5584768571703. Delta is -43.77340331507685\n",
            "WARNING:hmmlearn.base:Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2312.9060984881985 is not greater than 2355.927826648512. Delta is -43.021728160313614\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2279.27273378607 is not greater than 2346.7013284699246. Delta is -67.4285946838545\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2135.078547619224 is not greater than 2266.8279007415967. Delta is -131.74935312237267\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2322.945771769388 is not greater than 2513.8876457748274. Delta is -190.94187400543933\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2214.837578416737 is not greater than 2373.6144397530747. Delta is -158.7768613363378\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2154.190626450027 is not greater than 2158.796507733805. Delta is -4.605881283777762\n",
            "WARNING:hmmlearn.base:Model is not converging.  Current: 2220.7102965822937 is not greater than 2299.3768755613983. Delta is -78.66657897910454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MwYFCiknJHM",
        "outputId": "479323f6-b463-4f80-bf72-b3c5c710df7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_components': 2,\n",
              " 'val_Accuracy': 0.85,\n",
              " 'val_f1_micro': 0.85,\n",
              " 'val_f1_macro': 0.8269149831649832,\n",
              " 'val_precision_micro': 0.85,\n",
              " 'val_precision_macro': 0.8335137085137085,\n",
              " 'val_recall_micro': 0.85,\n",
              " 'val_recall_macro': 0.85,\n",
              " 'test_Accuracy': 0.875,\n",
              " 'test_f1_micro': 0.875,\n",
              " 'test_f1_macro': 0.8650575610273394,\n",
              " 'test_precision_micro': 0.875,\n",
              " 'test_precision_macro': 0.917810698073856,\n",
              " 'test_recall_micro': 0.875,\n",
              " 'test_recall_macro': 0.875}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_output[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tIE1TAKp51j",
        "outputId": "50fb9c7f-d41e-46b1-9225-ae0c1bcbd09b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_components': 3,\n",
              " 'val_Accuracy': 0.8333333333333334,\n",
              " 'val_f1_micro': 0.8333333333333334,\n",
              " 'val_f1_macro': 0.805453342953343,\n",
              " 'val_precision_micro': 0.8333333333333334,\n",
              " 'val_precision_macro': 0.812037037037037,\n",
              " 'val_recall_micro': 0.8333333333333334,\n",
              " 'val_recall_macro': 0.8333333333333334,\n",
              " 'test_Accuracy': 0.8583333333333333,\n",
              " 'test_f1_micro': 0.8583333333333333,\n",
              " 'test_f1_macro': 0.8483744082428294,\n",
              " 'test_precision_micro': 0.8583333333333333,\n",
              " 'test_precision_macro': 0.9004569504569505,\n",
              " 'test_recall_micro': 0.8583333333333333,\n",
              " 'test_recall_macro': 0.8583333333333334}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = dict({})\n",
        "X_train = dict({})\n",
        "X_val = dict({})\n",
        "for i in range(12):\n",
        "  X_test[i] = []\n",
        "  X_train[i] = []\n",
        "  X_val[i] = []\n",
        "for f in range(len(file_list)):\n",
        "  file = file_list[f]\n",
        "  file_label = label[f]\n",
        "  feature = get_feature(str(path+file))\n",
        "  if file.split('_')[2] in [\"01\", \"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
        "    X_test[file_label].append(feature)\n",
        "  elif file.split('_')[2] == [\"01\", \"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
        "    X_val[file_label].append(feature)\n",
        "  else:\n",
        "    X_train[file_label].append(feature)"
      ],
      "metadata": {
        "id": "-FzXyA50s6Nn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self identified test_split\n",
        "def my_train_test_split_user_independent(test_patient,val_patient,train_patient):\n",
        "  X_test = dict({})\n",
        "  X_train = dict({})\n",
        "  X_val = dict({})\n",
        "  for i in range(12):\n",
        "    X_test[i] = []\n",
        "    X_train[i] = []\n",
        "    X_val[i] = []\n",
        "  for p in train_patient:\n",
        "    path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+p+\"/isolated_strokes/\")\n",
        "    label,file_list = get_file_list(path)\n",
        "    for i in range(len(file_list)):\n",
        "      file_p = file_list[i]\n",
        "      file_label = label[i]\n",
        "      feature = get_feature(str(path+file_p))\n",
        "      if file_p.split('_')[2] in [\"01\", \"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
        "        X_train[file_label].append(feature)\n",
        "        \n",
        "  path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+test_patient+\"/isolated_strokes/\")\n",
        "  label,file_list = get_file_list(path)\n",
        "  for i in range(len(file_list)):\n",
        "    file_p = file_list[i]\n",
        "    file_label = label[i]\n",
        "    feature = get_feature(str(path+file_p))\n",
        "    if file_p.split('_')[2] in [\"01\", \"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
        "      X_test[file_label].append(feature)\n",
        "    \n",
        "  path = str(\"drive/MyDrive/Colab_Notebooks/EOG_data/isolated/\"+val_patient+\"/isolated_strokes/\")\n",
        "  label,file_list = get_file_list(path)\n",
        "  for i in range(len(file_list)):\n",
        "    file_p = file_list[i]\n",
        "    file_label = label[i]\n",
        "    feature = get_feature(str(path+file_p))\n",
        "    if file_p.split('_')[2] in [\"01\", \"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]:\n",
        "      X_val[file_label].append(feature)\n",
        "\n",
        "  return X_train,X_test, X_val"
      ],
      "metadata": {
        "id": "3SayrsvMsjm2"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = []\n",
        "val_label = []\n",
        "test_pred = []\n",
        "test_label = []\n",
        "for t in range(len(val_split)):\n",
        "  X_train,X_test,X_val= my_train_test_split_user_dependent(path,test_split[t],val_split[t],file_list,label)\n",
        "  clf_list = []\n",
        "  for k in range(12):\n",
        "    X_train_stroke = np.array(X_train[k])\n",
        "    clf = hmm.GaussianHMM(n_components=3, random_state=42)\n",
        "    clf.fit(X_train_stroke)\n",
        "    clf_list.append(clf)\n",
        "  pred = np.zeros((3,12))\n",
        "  for i in range(12):\n",
        "    score = np.zeros((3,12))\n",
        "    for j in range(12):\n",
        "      X_val_stroke = np.array(X_val[i])\n",
        "      X_test_stroke = np.array(X_test[i])\n",
        "      clf = clf_list[j]\n",
        "      score[0,j] = clf.score(X_val_stroke)\n",
        "      score[1,j] = clf.score(X_test_stroke[0].reshape(1, -1))\n",
        "      score[2,j] = clf.score(X_test_stroke[1].reshape(1, -1))\n",
        "    pred[:,i] = np.argmax(score,axis=1)\n",
        "  val_pred.extend(list(pred[0,:]))\n",
        "  val_label.extend(list(np.arange(12)))\n",
        "  test_pred.extend(list(pred[1,:]))\n",
        "  test_pred.extend(list(pred[2,:]))\n",
        "  test_label.extend(list(np.arange(12)))\n",
        "  test_label.extend(list(np.arange(12)))\n",
        "val_f1_micro,val_f1_macro,val_precision_micro,val_precision_macro,val_recall_micro,val_recall_macro,val_acc = evaluate(val_label,val_pred)\n",
        "test_f1_micro,test_f1_macro,test_precision_micro,test_precision_macro,test_recall_micro,test_recall_macro,test_acc = evaluate(test_label,test_pred)\n",
        "print(\"validation f1 micro:\", val_f1_micro)\n",
        "print(\"validation f1 macro:\", val_f1_macro)\n",
        "print(\"validation precision micro\", val_precision_micro)\n",
        "print(\"validation precision macro\", val_precision_macro)\n",
        "print(\"validation recall micro\", val_recall_micro)\n",
        "print(\"validation recall macro\", val_recall_macro)\n",
        "print(\"validation accuracy\", val_acc)\n",
        "print(\"test f1 micro:\", test_f1_micro)\n",
        "print(\"test f1 macro:\", test_f1_macro)\n",
        "print(\"test precision micro\", test_precision_micro)\n",
        "print(\"test precision macro\", test_precision_macro)\n",
        "print(\"test recall micro\", test_recall_micro)\n",
        "print(\"test recall macro\", test_recall_macro)\n",
        "print(\"test accuracy\", test_acc)"
      ],
      "metadata": {
        "id": "gJPj3lVKvAlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_patien_list = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "val_patient_list = [\"002\",\"003\",\"004\",\"005\",\"006\",\"001\"]\n",
        "#test_patien_list = [\"001\",\"002\"]\n",
        "#val_patient_list = [\"002\",\"003\"]\n",
        "\n",
        "val_pred = []\n",
        "val_label = []\n",
        "test_pred = []\n",
        "test_label = []\n",
        "for t in range(len(test_patien_list)):\n",
        "  train_patient= [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "  test_patient = test_patien_list[t]\n",
        "  val_patient = val_patient_list[t]\n",
        "  train_patient.remove(test_patient)\n",
        "  train_patient.remove(val_patient)\n",
        "  X_train,X_test, X_val= my_train_test_split_user_independent(test_patient,val_patient,train_patient)\n",
        "  clf_list = []\n",
        "  for k in range(12):\n",
        "    X_train_stroke = np.array(X_train[k])\n",
        "    clf = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", random_state=42)\n",
        "    clf.fit(X_train_stroke)\n",
        "    clf_list.append(clf)\n",
        "  pred_val = np.zeros((10,12))\n",
        "  pred_test = np.zeros((10,12))\n",
        "  for i in range(12):\n",
        "    score_val = np.zeros((10,12))\n",
        "    score_test = np.zeros((10,12))\n",
        "    for j in range(12):\n",
        "      X_val_stroke = np.array(X_val[i])\n",
        "      X_test_stroke = np.array(X_test[i])\n",
        "      clf = clf_list[j]\n",
        "      for d in range(X_val_stroke.shape[0]):\n",
        "        score_val[d,j] = clf.score(X_val_stroke[d,:].reshape(1, -1))\n",
        "      for d in range(X_test_stroke.shape[0]):\n",
        "        score_test[d,j] = clf.score(X_test_stroke[d,:].reshape(1, -1))\n",
        "    pred_val[:,i] = np.argmax(score_val,axis=1)\n",
        "    pred_test[:,i] = np.argmax(score_test,axis=1)\n",
        "  for pred in range(pred_val.shape[0]):\n",
        "    val_pred.extend(list(pred_val[pred,:]))\n",
        "    val_label.extend(list(np.arange(12)))\n",
        "  for pred in range(pred_test.shape[0]):\n",
        "    test_pred.extend(list(pred_test[pred,:]))\n",
        "    test_label.extend(list(np.arange(12)))\n",
        "val_f1_micro,val_f1_macro,val_precision_micro,val_precision_macro,val_recall_micro,val_recall_macro,val_acc = evaluate(val_label,val_pred)\n",
        "test_f1_micro,test_f1_macro,test_precision_micro,test_precision_macro,test_recall_micro,test_recall_macro,test_acc = evaluate(test_label,test_pred)\n",
        "print(\"validation f1 micro:\", val_f1_micro)\n",
        "print(\"validation f1 macro:\", val_f1_macro)\n",
        "print(\"validation precision micro\", val_precision_micro)\n",
        "print(\"validation precision macro\", val_precision_macro)\n",
        "print(\"validation recall micro\", val_recall_micro)\n",
        "print(\"validation recall macro\", val_recall_macro)\n",
        "print(\"validation accuracy\", val_acc)\n",
        "print(\"test f1 micro:\", test_f1_micro)\n",
        "print(\"test f1 macro:\", test_f1_macro)\n",
        "print(\"test precision micro\", test_precision_micro)\n",
        "print(\"test precision macro\", test_precision_macro)\n",
        "print(\"test recall micro\", test_recall_micro)\n",
        "print(\"test recall macro\", test_recall_macro)\n",
        "print(\"test accuracy\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWDiziUPp74J",
        "outputId": "aab46b2d-8614-4bd4-af42-4e89645fc73d"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation f1 micro: 0.45416666666666666\n",
            "validation f1 macro: 0.4596125878628175\n",
            "validation precision micro 0.45416666666666666\n",
            "validation precision macro 0.48979554156904165\n",
            "validation recall micro 0.45416666666666666\n",
            "validation recall macro 0.45416666666666666\n",
            "validation accuracy 0.45416666666666666\n",
            "test f1 micro: 0.5055555555555555\n",
            "test f1 macro: 0.5236143113608338\n",
            "test precision micro 0.5055555555555555\n",
            "test precision macro 0.5751105235832565\n",
            "test recall micro 0.5055555555555555\n",
            "test recall macro 0.5055555555555556\n",
            "test accuracy 0.5055555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_patien_list = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "val_patient_list = [\"002\",\"003\",\"004\",\"005\",\"006\",\"001\"]\n",
        "#test_patien_list = [\"001\",\"002\"]\n",
        "#val_patient_list = [\"002\",\"003\"]\n",
        "\n",
        "val_pred = []\n",
        "val_label = []\n",
        "test_pred = []\n",
        "test_label = []\n",
        "for t in range(len(test_patien_list)):\n",
        "  train_patient= [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "  test_patient = test_patien_list[t]\n",
        "  val_patient = val_patient_list[t]\n",
        "  train_patient.remove(test_patient)\n",
        "  train_patient.remove(val_patient)\n",
        "  X_train,X_test, X_val= my_train_test_split_user_independent(test_patient,val_patient,train_patient)\n",
        "  clf_list = []\n",
        "  for k in range(12):\n",
        "    X_train_stroke = np.array(X_train[k])\n",
        "    clf = hmm.GaussianHMM(n_components=2, covariance_type=\"spherical\", random_state=42)\n",
        "    clf.fit(X_train_stroke)\n",
        "    clf_list.append(clf)\n",
        "  pred_val = np.zeros((10,12))\n",
        "  pred_test = np.zeros((10,12))\n",
        "  for i in range(12):\n",
        "    score_val = np.zeros((10,12))\n",
        "    score_test = np.zeros((10,12))\n",
        "    for j in range(12):\n",
        "      X_val_stroke = np.array(X_val[i])\n",
        "      X_test_stroke = np.array(X_test[i])\n",
        "      clf = clf_list[j]\n",
        "      for d in range(X_val_stroke.shape[0]):\n",
        "        score_val[d,j] = clf.score(X_val_stroke[d,:].reshape(1, -1))\n",
        "      for d in range(X_test_stroke.shape[0]):\n",
        "        score_test[d,j] = clf.score(X_test_stroke[d,:].reshape(1, -1))\n",
        "    pred_val[:,i] = np.argmax(score_val,axis=1)\n",
        "    pred_test[:,i] = np.argmax(score_test,axis=1)\n",
        "  for pred in range(pred_val.shape[0]):\n",
        "    val_pred.extend(list(pred_val[pred,:]))\n",
        "    val_label.extend(list(np.arange(12)))\n",
        "  for pred in range(pred_test.shape[0]):\n",
        "    test_pred.extend(list(pred_test[pred,:]))\n",
        "    test_label.extend(list(np.arange(12)))\n",
        "val_f1_micro,val_f1_macro,val_precision_micro,val_precision_macro,val_recall_micro,val_recall_macro,val_acc = evaluate(val_label,val_pred)\n",
        "test_f1_micro,test_f1_macro,test_precision_micro,test_precision_macro,test_recall_micro,test_recall_macro,test_acc = evaluate(test_label,test_pred)\n",
        "print(\"validation f1 micro:\", val_f1_micro)\n",
        "print(\"validation f1 macro:\", val_f1_macro)\n",
        "print(\"validation precision micro\", val_precision_micro)\n",
        "print(\"validation precision macro\", val_precision_macro)\n",
        "print(\"validation recall micro\", val_recall_micro)\n",
        "print(\"validation recall macro\", val_recall_macro)\n",
        "print(\"validation accuracy\", val_acc)\n",
        "print(\"test f1 micro:\", test_f1_micro)\n",
        "print(\"test f1 macro:\", test_f1_macro)\n",
        "print(\"test precision micro\", test_precision_micro)\n",
        "print(\"test precision macro\", test_precision_macro)\n",
        "print(\"test recall micro\", test_recall_micro)\n",
        "print(\"test recall macro\", test_recall_macro)\n",
        "print(\"test accuracy\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsqMDa7TwVwg",
        "outputId": "2f48aa6d-a756-408d-8aa5-e2dba4deea03"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation f1 micro: 0.5111111111111111\n",
            "validation f1 macro: 0.5197631658732306\n",
            "validation precision micro 0.5111111111111111\n",
            "validation precision macro 0.5639324267590504\n",
            "validation recall micro 0.5111111111111111\n",
            "validation recall macro 0.5111111111111111\n",
            "validation accuracy 0.5111111111111111\n",
            "test f1 micro: 0.5194444444444445\n",
            "test f1 macro: 0.5360116176840183\n",
            "test precision micro 0.5194444444444445\n",
            "test precision macro 0.6098945369301004\n",
            "test recall micro 0.5194444444444445\n",
            "test recall macro 0.5194444444444445\n",
            "test accuracy 0.5194444444444445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnowstkI3n4M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}