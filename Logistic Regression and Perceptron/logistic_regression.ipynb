{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZMEjTi0Ag1Sx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "def preprocess(data):\n",
        "  # Delete silent part\n",
        "  data = data.astype(float)\n",
        "  n_size = 50\n",
        "  n_len = int(data.shape[0]/n_size)\n",
        "  std_data = np.zeros((n_size, 2))\n",
        "  for i in range(n_size):\n",
        "    seg_data_x = data[i*n_len:i*n_len+n_len, 0]\n",
        "    seg_data_y = data[i*n_len:i*n_len+n_len, 1]\n",
        "    std_data[i, 0] = np.std(seg_data_x)\n",
        "    std_data[i, 1] = np.std(seg_data_y)\n",
        "  pass_threshold = 1\n",
        "  pass_idx_x = np.where(std_data[:,0] >= pass_threshold)[0]\n",
        "  pass_idx_y = np.where(std_data[:,1] >= pass_threshold)[0]\n",
        "  if len(pass_idx_x) == 0:\n",
        "    start_idx = max(0, pass_idx_y[0] - 1)\n",
        "    end_idx = min(data.shape[0],pass_idx_y[-1] + 1)\n",
        "  elif len(pass_idx_y) == 0:\n",
        "    start_idx = max(0, pass_idx_x[0] - 1)\n",
        "    end_idx = min(data.shape[0],pass_idx_x[-1] + 1)\n",
        "  else:\n",
        "    start_idx = max(0,min(pass_idx_x[0], pass_idx_y[0]) - 1)\n",
        "    end_idx = min(data.shape[0],max(pass_idx_x[-1], pass_idx_y[-1]) + 1)\n",
        "  \n",
        "  # resample to 100 data points\n",
        "  data = signal.resample(data[start_idx*n_len:end_idx*n_len, :], 100, axis=0)\n",
        "  # scale\n",
        "  data = (data - data.min(axis=0, keepdims=True))/(data.max(axis=0, keepdims=True) - data.min(axis=0, keepdims=True))\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "WRtSOG0sjQzq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W__iF6fHhC4N",
        "outputId": "34579ee1-ccd3-428b-c064-055e3142acc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = '/content/drive/MyDrive/S1Database/isolated/'\n",
        "os.listdir(main_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo3csk7aiimC",
        "outputId": "8dd6226e-00fb-428d-c51a-362e54f8dd8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ReadMe', '004', '002', '006', '003', '005', '001']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get file list for 1 patient\n",
        "def get_file_list(path):\n",
        "    file_list = []\n",
        "    label = []\n",
        "    for i in os.listdir(path):\n",
        "        file_list.append(i)\n",
        "        l = int(i.split(\"_\")[-1].split(\".\")[0])-1\n",
        "        label.append(l)\n",
        "    return label,file_list"
      ],
      "metadata": {
        "id": "3Q3nd_c5aeY6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature from 1 file and preprocess\n",
        "def get_feature(path):\n",
        "    f = []\n",
        "    a = pd.read_csv(path,names=[\"vertical\",\"horizontal\"])\n",
        "    a = np.array(a)\n",
        "    #print(a.shape)\n",
        "    a = preprocess(a)\n",
        "    #print(a.shape)\n",
        "    f.append(a)        \n",
        "\n",
        "    return f\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "_C7ev7Ltae-0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self identified test_split\n",
        "def my_train_test_split_user_dependent(path,test_split,file_list,label):\n",
        "    X_test = []\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    for f in range(len(file_list)):\n",
        "        file = file_list[f]\n",
        "        file_label = label[f]\n",
        "        feature = get_feature(str(path+file))\n",
        "        #print(file.split('_')[2],file_label)\n",
        "        if file.split('_')[2] in test_split:\n",
        "            X_test.append(feature)\n",
        "            y_test.append(file_label)\n",
        "            #print(file,len(feature))\n",
        "        else:\n",
        "            X_train.append(feature)\n",
        "            y_train.append(file_label)\n",
        "            #print(file)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train,X_test, y_train,y_test"
      ],
      "metadata": {
        "id": "82EHpPbcaigs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred,y_prob):\n",
        "    f1_micro = f1_score(y_true, y_pred,average = 'micro')\n",
        "    f1_macro = f1_score(y_true, y_pred,average = 'macro')\n",
        "    precision_micro = precision_score(y_true, y_pred, average='micro')\n",
        "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    recall_micro = recall_score(y_true, y_pred, average='micro')\n",
        "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc"
      ],
      "metadata": {
        "id": "aDrRqpLCajPo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class classficiation(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(classficiation, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(2, 32, 12, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        conv_output_size = (input_size - 12 + 2 * 1) / 1 + 1\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(int(32 * conv_output_size), num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # Move the channel dimension to the correct position\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "input_size = 100\n",
        "num_classes = 12\n",
        "model = classficiation(input_size, num_classes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Za-VMCV4mqEB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom dataset class\n",
        "class MYDataset(Dataset):\n",
        "    def __init__(self, feature,label):\n",
        "      self.feature = []\n",
        "      self.label = []\n",
        "      for i in range(len(feature)):\n",
        "        self.feature.append(feature[i])\n",
        "        self.label.append(label[i])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f = self.feature[idx]\n",
        "        #f = f[np.newaxis,:,:]\n",
        "        l = self.label[idx]\n",
        "        return f, l\n"
      ],
      "metadata": {
        "id": "sHLZfBH7jDuz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MYDataset(Dataset):\n",
        "    def __init__(self, feature, label):\n",
        "        self.feature = []\n",
        "        self.label = []\n",
        "        for i in range(len(feature)):\n",
        "            self.feature.append(feature[i])\n",
        "            self.label.append(label[i])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f = self.feature[idx]\n",
        "        f = f.reshape(100, 2)  # Ensure the input tensor has the shape (100, 2)\n",
        "        l = self.label[idx]\n",
        "        return f, l\n"
      ],
      "metadata": {
        "id": "jtsuLIEbIdDc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Dependent"
      ],
      "metadata": {
        "id": "NmDSs32daleL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "test_split = [[\"01\",\"02\"],[\"03\",\"04\"],[\"05\",\"06\"],[\"07\",\"08\"],[\"09\",\"10\"]]"
      ],
      "metadata": {
        "id": "Ccmxt05oa_EH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### def training\n",
        "def train(model,train_dataloader,num_epochs,optimizer,criterion):\n",
        "  train_loss = []\n",
        "  model = model.to(device)\n",
        "  for epoch in range(num_epochs):\n",
        "        #print(\"running epoch: \", epoch)\n",
        "        model.train()\n",
        "        Loss = 0\n",
        "        train_label = []\n",
        "        train_ypred = []\n",
        "        for i, (feature,label) in enumerate(train_dataloader, 0):\n",
        "          #print(feature.shape)\n",
        "          optimizer.zero_grad()\n",
        "          feature = feature.to(device)\n",
        "          output = model(feature.float())\n",
        "          ypred = torch.argmax(output.cpu(),dim=1)\n",
        "          #print(feature.shape,output.shape)\n",
        "          #print(ypred)\n",
        "          for j in ypred:\n",
        "            train_ypred.append(j)\n",
        "          for j in label:\n",
        "            train_label.append(j)\n",
        "          loss = criterion(output,label.to(device))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          Loss += loss.item()\n",
        "        Loss = Loss/(i+1)\n",
        "        acc = accuracy_score(y_true=train_label, y_pred= train_ypred)\n",
        "        train_loss.append(Loss)\n",
        "  #model.eval()\n",
        "\n",
        "        #print(\"train loss: \",Loss,\" train accuracy: \",acc)\n",
        "  return model"
      ],
      "metadata": {
        "id": "mzYAzfmtdC0x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model,test_dataloader,m):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    label_list = []\n",
        "    ypred_list = []\n",
        "    yprob_list = []\n",
        "        #Loss = 0\n",
        "    for i, (feature,label) in enumerate(test_dataloader, 0):\n",
        "      feature = feature.to(device)\n",
        "      output = model(feature.float())\n",
        "      #print(output.shape)\n",
        "      ypred = torch.argmax(output,dim=1)\n",
        "      yprob = m(output)\n",
        "      for j in ypred.cpu().detach().numpy():\n",
        "        ypred_list.append(j)\n",
        "      for l in label.cpu().detach().numpy():\n",
        "        label_list.append(l)\n",
        "      for l in yprob.cpu().detach().numpy():\n",
        "        yprob_list.append(l)\n",
        "    f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc = evaluate(label_list, ypred_list,yprob_list)\n",
        "\n",
        "    #print(\"test acc: \", acc)\n",
        "    return f1_micro,f1_macro,precision_micro,precision_macro,recall_micro,recall_macro,acc"
      ],
      "metadata": {
        "id": "Jdv9FLbuiNL-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train 5-fold cross validation"
      ],
      "metadata": {
        "id": "e1In2rSmc9fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "m = nn.Softmax(dim=1).to(device)\n",
        "total_acc = []\n",
        "total_f1_micro = []\n",
        "total_f1_macro = []\n",
        "total_recall_micro = []\n",
        "total_recall_macro = []\n",
        "total_precision_micro = []\n",
        "total_precision_macro = []\n",
        "for p in patient:\n",
        "    #print(p)\n",
        "    output_pck = []\n",
        "    path = str(main_dir+p+\"/isolated_strokes/\")\n",
        "    acc = 0 \n",
        "    f1_macro =0\n",
        "    f1_micro =0\n",
        "    recall_micro =0\n",
        "    recall_macro =0\n",
        "    precision_micro =0\n",
        "    precision_macro =0\n",
        "    for t in test_split:\n",
        "        label,file_list = get_file_list(path)\n",
        "        X_train,X_test, y_train,y_test = my_train_test_split_user_dependent(path,t,file_list,label)\n",
        "        #print(X_train.shape,X_test.shape, y_train.shape,y_test.shape)\n",
        "        train_data = MYDataset(X_train,y_train)\n",
        "        train_dataloader  = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        test_data = MYDataset(X_test,y_test)\n",
        "        test_dataloader  = DataLoader(test_data, batch_size=16, shuffle=True)\n",
        "        \n",
        "        # set new model\n",
        "        torch.manual_seed(42)\n",
        "       \n",
        "        lr = 0.0001\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        num_epochs = 50\n",
        "        # train \n",
        "        model = train(model,train_dataloader,num_epochs,optimizer,criterion)\n",
        "        # evaluate \n",
        "        f1_mi,f1_ma,precision_mi,precision_ma,recall_mi,recall_ma,accuracy = eval(model,test_dataloader,m)\n",
        "        acc += accuracy\n",
        "        f1_macro += f1_ma\n",
        "        f1_micro += f1_mi\n",
        "        recall_micro += recall_mi\n",
        "        recall_macro += recall_ma\n",
        "        precision_micro += precision_mi\n",
        "        precision_macro += precision_ma\n",
        "    \n",
        "    print(p,acc/5,f1_macro/5,f1_micro/5,recall_micro/5,recall_macro/5,precision_micro/5,precision_macro/5)\n",
        "    total_acc.append(acc/5)\n",
        "    total_f1_micro.append(f1_micro/5)\n",
        "    total_f1_macro.append(f1_macro/5)\n",
        "    total_recall_micro.append(recall_micro/5)\n",
        "    total_recall_macro.append(recall_macro/5)\n",
        "    total_precision_micro.append(precision_micro/5)\n",
        "    total_precision_macro.append(precision_macro/5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2EPludVf_YG",
        "outputId": "1e5f36e2-bba7-4b5f-e225-b919b8c47bdf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001 0.6583333333333332 0.5924074074074074 0.6583333333333332 0.6583333333333332 0.6583333333333332 0.6583333333333332 0.5942063492063492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002 0.825 0.7961111111111111 0.825 0.825 0.825 0.825 0.8111111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "003 0.65 0.5754761904761905 0.65 0.65 0.65 0.65 0.5733333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "004 0.5999999999999999 0.5324603174603174 0.5999999999999999 0.5999999999999999 0.5999999999999999 0.5999999999999999 0.5297222222222223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "005 0.7985507246376812 0.7677777777777778 0.7985507246376812 0.7985507246376812 0.8 0.7985507246376812 0.7791666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "006 0.875 0.850079365079365 0.875 0.875 0.875 0.875 0.8594444444444443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total acc\",np.mean(np.array(total_acc)))\n",
        "print(\"f1_macro\",np.mean(np.array(total_f1_macro)))\n",
        "print(\"f1_micro\",np.mean(np.array(total_f1_micro)))\n",
        "print(\"total_recall_micro\",np.mean(np.array(total_recall_micro)))\n",
        "print(\"total_recall_macro\",np.mean(np.array(total_recall_macro)))\n",
        "print(\"total_precision_micro\",np.mean(np.array(total_precision_micro)))\n",
        "print(\"total_precision_macro\",np.mean(np.array(total_precision_macro)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC2of8dv7y_g",
        "outputId": "e161274e-07b7-4bff-bdc9-5350d32f85a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total acc 0.7344806763285024\n",
            "f1_macro 0.6857186948853616\n",
            "f1_micro 0.7344806763285024\n",
            "total_recall_micro 0.7344806763285024\n",
            "total_recall_macro 0.7347222222222222\n",
            "total_precision_micro 0.7344806763285024\n",
            "total_precision_macro 0.6911640211640212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########training\n",
        "for p in patient:\n",
        "    print(p)\n",
        "    path = str(main_dir+p+\"/isolated_strokes/\")\n",
        "    label,file_list = get_file_list(path)\n",
        "    X = []\n",
        "    y = []\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    for f in range(len(file_list)):\n",
        "        file = file_list[f]\n",
        "        file_label = label[f]\n",
        "        feature = get_feature(str(path+file))\n",
        "        #print(file.split('_')[2],file_label)\n",
        "        X.append(feature)\n",
        "        y.append(file_label)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    train_data = MYDataset(X,y)\n",
        "    train_dataloader  = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        # set new model\n",
        "    torch.manual_seed(42)\n",
        "   \n",
        "    lr = 0.0001\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    num_epochs = 50\n",
        "        # train \n",
        "    model = train(model,train_dataloader,num_epochs,optimizer,criterion)\n",
        "    '''state_dict = model.state_dict()\n",
        "    torch.save(state_dict, str('drive/MyDrive/2023JHU/MLMA_EOG/checkpoint/CNN_sub'+str(p)+'.pth'))'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z166IouhpOCa",
        "outputId": "a16e2082-58e7-447f-b62e-9cceb87f804b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001\n",
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split on patient level - User-independent"
      ],
      "metadata": {
        "id": "48eGmXRonF8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# self identified test_split\n",
        "def my_train_test_split_user_independent(test_patient,train_patient):\n",
        "    X_test = []\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    for p in train_patient:\n",
        "        path = str(main_dir+p+\"/isolated_strokes/\")\n",
        "        label,file_list = get_file_list(path)\n",
        "        for i in range(len(file_list)):\n",
        "            file = file_list[i]\n",
        "            file_label = label[i]\n",
        "            feature = get_feature(str(path+file))\n",
        "            X_train.append(feature)\n",
        "            y_train.append(file_label)\n",
        "        \n",
        "    path = str(main_dir+test_patient+\"/isolated_strokes/\")\n",
        "    label,file_list = get_file_list(path)\n",
        "    for i in range(len(file_list)):\n",
        "        file = file_list[i]\n",
        "        file_label = label[i]\n",
        "        feature = get_feature(str(path+file))\n",
        "        X_test.append(feature)\n",
        "        y_test.append(file_label)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train,X_test, y_train,y_test"
      ],
      "metadata": {
        "id": "BMnOdckV4u7R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "acc = 0 \n",
        "f1_macro =0\n",
        "f1_micro =0\n",
        "recall_micro =0\n",
        "recall_macro =0\n",
        "precision_micro =0\n",
        "precision_macro =0\n",
        "for test_patient in patient:\n",
        "    train_patient= [\"001\",\"002\",\"003\",\"004\",\"005\",\"006\"]\n",
        "    train_patient.remove(test_patient)\n",
        "    X_train,X_test, y_train,y_test = my_train_test_split_user_independent(test_patient,train_patient)\n",
        "    train_data = MYDataset(X_train,y_train)\n",
        "    train_dataloader  = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "    test_data = MYDataset(X_test,y_test)\n",
        "    test_dataloader  = DataLoader(test_data, batch_size=16, shuffle=True)\n",
        "        \n",
        "    # set new model\n",
        "    torch.manual_seed(42)\n",
        "    model = classficiation(input_size, num_classes)\n",
        "    lr = 0.0001\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    num_epochs = 50\n",
        "        # train \n",
        "    model = train(model,train_dataloader,num_epochs,optimizer,criterion)\n",
        "        # evaluate \n",
        "    # evaluate \n",
        "    f1_mi,f1_ma,precision_mi,precision_ma,recall_mi,recall_ma,accuracy = eval(model,test_dataloader,m)\n",
        "    acc += accuracy\n",
        "    f1_macro += f1_ma\n",
        "    f1_micro += f1_mi\n",
        "    recall_micro += recall_mi\n",
        "    recall_macro += recall_ma\n",
        "    precision_micro += precision_mi\n",
        "    precision_macro += precision_ma\n",
        "    \n",
        "print(acc/6,f1_macro/6,f1_micro/6,recall_micro/6,recall_macro/6,precision_micro/6,precision_macro/6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMEttfcR4X1b",
        "outputId": "9d550545-5be7-4127-ab15-aae34a3d4dac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5441358442848756 0.47144040186182073 0.5441358442848756 0.5441358442848756 0.5432379349046016 0.5441358442848756 0.5106152403398708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########training\n",
        "X = []\n",
        "y = []\n",
        "for p in patient:\n",
        "    print(p)\n",
        "    path = str(main_dir+p+\"/isolated_strokes/\")\n",
        "    label,file_list = get_file_list(path)\n",
        "    for f in range(len(file_list)):\n",
        "        file = file_list[f]\n",
        "        file_label = label[f]\n",
        "        feature = get_feature(str(path+file))\n",
        "        #print(file.split('_')[2],file_label)\n",
        "        X.append(feature)\n",
        "        y.append(file_label)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "train_data = MYDataset(X,y)\n",
        "train_dataloader  = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        # set new model\n",
        "torch.manual_seed(42)\n",
        "model = classficiation(input_size, num_classes)\n",
        "lr = 0.0001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 50\n",
        "        # train \n",
        "model = train(model,train_dataloader,num_epochs,optimizer,criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "tjbhdiW-0TZR",
        "outputId": "cd5bdae5-564b-4d37-9214-d43422bc4959"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "001\n",
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"state_dict = model.state_dict()\\ntorch.save(state_dict, 'drive/MyDrive/2023JHU/MLMA_EOG/checkpoint/CNN_subAll.pth')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}